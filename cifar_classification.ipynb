{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinLev/dotfiles/blob/master/cifar_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "eEt4AJqKVj0v"
      },
      "source": [
        "# CIFAR Classification\n",
        "\n",
        "### Exercise objectives\n",
        "\n",
        "- Implement a CNN for a 10-class classification problem\n",
        "- Enhance the CNN performance with data augmentation techniques\n",
        "- Experiment the acceleration of GPU for image processing (Google Colab)\n",
        "\n",
        "<hr>\n",
        "<hr>\n",
        "\n",
        "You should now have a better feeling of how a CNN is working, and especially how the convolutions are affecting the image to detect specific features. Therefore, let's now play with a bit more complex images. \n",
        "\n",
        "The CIFAR-10 dataset is a dataset that contains images of 10 different classes \n",
        "\n",
        "<img src=\"https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/mini-projets/cifar10_notebook_fichiers/cifar_10.png\">\n",
        "\n",
        "This dataset is emblematic in the research community as many enhancements for image problems have been achieved on this dataset, and later on the CIFAR-100 dataset once the performance got too high. You can check the [wikipedia](https://en.wikipedia.org/wiki/CIFAR-10) page of the dataset if you want to know more about it.\n",
        "\n",
        "In this notebook, we propose to implement a CNN to distinguish the 10 categories from the CIFAR-10 dataset. Again, remember that until 10 years ago, this problem was very challenging to the entire research community and is now for you to tackle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE3R20SasW6i"
      },
      "source": [
        "## 0. Colab\n",
        "\n",
        "**First, make sure to use GPU acceleration** by clicking on `\"Runtime --> Change runtime --> GPU\"` if you are on Colab. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ZY44N5e6T2Il"
      },
      "source": [
        "## 1. Data\n",
        "\n",
        "We'll take care of data loading and preprocessing for you. Just run the following cells and make sure you understand them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T17:24:01.063283Z",
          "start_time": "2021-04-28T17:23:56.485483Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkKdhZXWVj00",
        "outputId": "9d3cd054-55ab-400e-c92a-1f36a9f45b0a"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "\n",
        "(images_train, labels_train), (images_test, labels_test) = cifar10.load_data()\n",
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "print(images_train.shape, images_test.shape)\n",
        "unique, counts = np.unique(labels_train, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5000,\n",
              " 1: 5000,\n",
              " 2: 5000,\n",
              " 3: 5000,\n",
              " 4: 5000,\n",
              " 5: 5000,\n",
              " 6: 5000,\n",
              " 7: 5000,\n",
              " 8: 5000,\n",
              " 9: 5000}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI_3K-MHT2In"
      },
      "source": [
        "❗️ 50,000 images may take a long time to train: **Always start with a subsample to iterate quickly** before scaling up\n",
        "\n",
        "Below, we divide the dataset size by `reduction_factor=10`. Don't try to increase it unless we ask you too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T18:14:07.619432Z",
          "start_time": "2021-04-28T18:14:07.022874Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR_JXHmlT2Io",
        "outputId": "e6156de0-7196-4f6b-fb4c-e43ef7b918b5"
      },
      "source": [
        "# Reduce size\n",
        "reduction_factor = 10\n",
        "\n",
        "idx_train =  np.random.choice(len(images_train), round(len(images_train)/reduction_factor))\n",
        "idx_test =  np.random.choice(len(images_test), round(len(images_test)/reduction_factor))\n",
        "\n",
        "images_train_small = images_train[idx_train]\n",
        "images_test_small = images_test[idx_test]\n",
        "labels_train_small = labels_train[idx_train]\n",
        "labels_test_small = labels_test[idx_test]\n",
        "\n",
        "print(images_train.shape, images_test.shape)\n",
        "unique, counts = np.unique(labels_train_small, return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 467,\n",
              " 1: 503,\n",
              " 2: 502,\n",
              " 3: 508,\n",
              " 4: 492,\n",
              " 5: 508,\n",
              " 6: 525,\n",
              " 7: 506,\n",
              " 8: 467,\n",
              " 9: 522}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T17:25:40.424504Z",
          "start_time": "2021-04-28T17:25:40.022376Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "hQ62jK5VVj03",
        "outputId": "8eff6f39-577c-46fd-de95-17edb41558e0"
      },
      "source": [
        "# Let's plot few images to see what they look like\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(6):\n",
        "    plt.subplot(1,6, i+1)\n",
        "    img = images_train[i]\n",
        "    label = labels_train[i][0]\n",
        "    plt.imshow(img)\n",
        "    plt.title(labels[label])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAACmCAYAAABeF/fpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9aZQdx3UmeCOXt79Xr/YNBRQAAiC4k6IoidROyUtbtmTZ8jKnbXnabk/PjI/d0z5jq92eaZ8e97T8o93dHh/bbcu2ZHm3ZUmULLdMS6I2UqJIcQMIEDtQqH179fYlM2N+1NOL+C5QQK1AkbjfOTzMQOTLjIy4cSOy8vvuVVprEggEAoFAIBAIBALBzYVzsxsgEAgEAoFAIBAIBAJ5ORMIBAKBQCAQCASCXQF5ORMIBAKBQCAQCASCXQB5ORMIBAKBQCAQCASCXQB5ORMIBAKBQCAQCASCXQB5ORMIBAKBQCAQCASCXQB5OdsglFJHlFLPK6VKSqmfv9ntEdy6UEpppdRtN7sdglcfxHZuXSilPqqU+vWb3Q6BgIhIKfWEUupn1qjbq5QqK6Xc650ruDXxWrUfeTnbOH6JiL6ktc5qrX/rZjdGsLuhlLqglHrXzW6H4NUHsR2BQHAjsFs3rVrrS1rrjNY6vNltEawNsZ/th7ycbRz7iOj41Sq+83YuEKwHSinvZrdB8OqE2I5gN0HsUSAQCLYP8nK2ASilvkhE7yCi325/Kv1zpdTvKqU+p5SqENE7lFJH239FKCiljiulfsD6fa9S6jNKqaJS6ltKqV9XSn3tpj2QYEehlPo4Ee0los+07eWX2nSyn1ZKXSKiLyql3q6Uusx+1/liopRylVK/opQ626bSPquUGrvKvd6slJpQSr39RjybYGchtiPYLiil7ldKfbttA39FRAmr7j1tmn5BKfWkUuoeq25EKfUJpdS8Uuq8TeNXSv2aUupvlVJ/qpQqEtFP3dCHElwVSqkPWfP9ZaXUD7b//deUUn9qnTfe9ieeUuo/EtFbyOxrfrt9zsPtfcpK+/8PW79/or1/ebL9m8+09zd/Zu1vxq3z17xWGweVUk+3f/tppVQPb+caz/svlFInlFLLSqnPK6X2bVNX3pIQ+9lF9qO1lv828B8RPUFEP9M+/igRrRDRI7T6opslojNE9CtEFCOidxJRiYiOtM//y/Z/KSK6g4gmiOhrN/uZ5L8dtZcLRPSu9vE4EWki+hMiShNRkojeTkSXr/Gb/5OIXiKiI0SkiOheIupt12kiuo2IvqdtSw/d7OeV/8R25L/d8197HbpIRP8HEflE9MNE1CKiXyei+4lojojeQEQuEX2wbT/x9nr2LBH93+1rHCCic0T03e3r/lr7Ou9rn5u82c8q/2kiog8Q0Uh7TH6UiCpENNwerz+1zvuOP/Ha5Seova9pl3uIaJmIfoKIPCL68Xa51zr/DBEdJKIuInqZiE4R0bva5/8JEf3xBq41SUR3tX3bJ77T1mu1k4je227D0fZ1f5WInrzZY/Bq/k/sZ/fYj3w52zo+rbX+utY6IqL7iChDRB/WWje11l8kos8S0Y+rVcrjDxHRv9daV7XWLxPRx25eswU3Eb+mta5orWvrOPdniOhXtdav6FW8oLVetOo/QET/nYi+V2v99I60VrCbILYj2AjeSKsvZf9Va93SWv8tEX2rXfezRPTftdbf1FqHWuuPEVGj/ZvXE1G/1vo/tNeyc0T0B0T0Y9a1n9Jaf0prHa3THgU7DK3132itp9pj8ldEdJqIHtrEpb6PiE5rrT+utQ601n9BRCeJ6Putc/5Ya31Wa71CRP9ARGe11v+ktQ6I6G9o9eV/vdf6uNb6mNa6QkT/FxH9iLq+TORfEdF/0lqfaN/z/yWi+3bV149XGcR+do/9yMvZ1jFhHY8Q0UT7Re07uEhEo0TUT6tv5xNr/FZw62Aj4z5GRGevUf+vieivtdbHttYkwasEYjuCjWCEiCZ1+0/FbVxs/38fEf1im9JYUEoVaNVmRtp1I6zuV4ho0LqOrF+7DEqpn7RoqgVa/ZrQt4lLjZCxk+/gO3uZ72DWOq5dpZzZwLUmWJ1P12/3PiL6b9azLtEqQ2D02j8TrAWxn91jP/JytnXYi94UEY0ppex+3Uurn1zniSggoj1W3RX6D8FrDvo6/1ahVZorEXWCyvRb9RO0+ul/LXyAiN6nlPqFrTRSsCshtiPYKqaJaFQppax/29v+/wQR/Uetdd76L9X+y/QEEZ1ndVmt9T+zrnM1+xTcJLT/4v8HRPRztEr5yhPRMVrdcIKvIKIh9nM+llO0unm18Z29zEaxnmuNsboWES1c57oTRPS/MBtNaq2f3EQbb3mI/ewu+5GXs+3FN4moSkS/pJTy1arA/vuJ6C/1aijPvyOiX1NKpZRStxPRT968pgpuEGZpVa+xFk4RUUIp9X1KKZ9Wec9xq/4jRPT/KKUOqVXco5TqteqniOhRIvoFpdT/ut2NF9xUiO0ItoqnaPWPgj/fXpPeT4am9AdE9K+UUm9o20e6bUtZInqaiEpKqV9WSiXVanCZu5RSr79JzyG4PtK0ukmeJyJSSv3PtPrlg4joeSJ6q1rN+9RFRP+W/Zb7ms8R0WGl1P/UDvrwo7Sqk//sJtq1nmv9c6XUHUqpFBH9ByL6W3398Oe/R0T/Vil1JxGRUqpLKfWBTbRPsAqxn11kP/Jyto3QWjdp9WXse2n1rf13iOgntdYn26f8HK2KH2eI6ONE9Be0yvEXvHbxn4joV9ufzX+YV7b51v8brW6kJ2n1L1R2BL7fJKK/JqJ/JKIiEf0hrQaDsK9xiVY32R9SuzDXiGDTENsRbAntNen9tBpNcYlWRf5/1657hoj+JRH9Nq0K7M+0z6P2xuY9tKqjPk+r69lHaHX9EuxCtHXs/5lWX8hniehuIvp6u+5xIvorInqRVgO98E3yfyOiH25Hrfuttjb1PUT0i0S0SKv5Xd+jtb7e14irtWs91/o4rQZYm6HVaKI/T9eB1vqTRPQbRPSXajVi6DFa3XsJNgGxn91lPwqp6IIbCaXUbxDRkNb6gze7LQKBQCAQCAQCgeDmQr6c3UAopW5vU4uUUuohIvppIvrkzW6XQCAQCAQCgUAguPm4amI2wY4hS6tUxhFa/Wz8n4no0ze1RQKBQCAQCAQCgWBXQGiNAoFAIBAIBAKBQLALsCVao1Lqe5RSryilziilPrRdjRLcGhD7EWwWYjuCrUDsR7BZiO0ItgKxH8F6sOkvZ+2cOqeI6N20GiHsW0T04+2IL1eF7/s6nkh0ymFoIl06LE2Cq6BIMQ/fI32r7LmYCBxTuhBh2jFazdrQRhBgtE3eGy6/ttVfEeSaJtIR/lo57CEsRBHel9/nivOteyliz8fKDruW65jn530TsfHXtHabua3YpaVCicrV+to/Ztio/WRzXbp3wOQ/bdarneOgWWftxGb4sQSUY3FTdv0Y1DlszOq1MpSbjZq5T4hjeL1xUNY4pDNZqIvHsY06DKBcq1XtWqjjdliv1aAcWte6YgyZwQcBXiuybFqz+3iex8r4vJpM//D7RHgpWikUF7TW/bQObMb39PX16fHx8fVc/jWBiHVwEBgbuGKcmN9yHPSX6MfQxrm/XLcD2EZcuHCBFhYWdsz3OI7SnrXeOLYP5WvNlXdj5bXX24D5E4etW3aJ+21ifsth7bLH1HVx3obM10TR2m3ktsIfjz+tvd64bFH3mf9otVrYLusZeZuv9CfYdzF/7TWPl5dXajvqe3Jded0/MGy33roeG2OHzy+Hla228H3AtYcGf62uPY+vmNca7wznspOvsJ5rzcwtMLc28ssrb3PtX+s1jvnFFuemqFRc3rl9TyKh+7JmrwBzk8+9mA/lgPnxlDX/mtUq1BUqbM9wjXl+xRxn93HZvHat6gRrYzaTgjLfnwShte91cN2qNZpQLpUqa7eZNdrl/pHVg3+9zuS4Yk9tncC2U1fM0ZVKZU3fsxXN2UNEdEZrfa7dwL8kovcS0ZpOKp5I0H0PvK5TLhSWTJ2DT9ETw6fY24uD2N+T7hz35TNQF3PRALw4RI8mshz90nIBqpoB3rc7j5GDndAsII0GRsGv1/ElIZHEDXdobVarbNPflc9hG1mKhqZliC7h8/EXu2wG+yOdNn3l+9gmbuCav8g6pq+a7NzAegn6jT/8BG0QG7Kf3oFB+ne/+Tud8uWTz3aO58+fgHPDEM16cO/tUN578GjnuHtoL9QlkvjbU8cxH+HFMy92jlslHEOX3TfXjbbjJYwNP/TIW6HutsPYxvrKEpSPH3uucxxFOA7NFtrdy8dfgnKxYCLONppos60m2s7SIjrtctVcOwjxt/39PVDu7kG7C3XJ/Bb3XVSv4Tz79Cf/8SKtHxv2PePj4/TMM890yvzl5VWH6ywQtQqO4+KSsYGenm6oC9kfN5Ip9LVuzKRO4/4hYkv1tf/EtDN46KGHrn8S+wltwH48z6HBPuM3k0mznvB+99gGgr/oBvZLBPttYaUI5YSDfzhKW7641MDNlJOKQzkZZ7+11oCurjzULS+jr2lWcJ7bptZqsonMNz3sxd9+SepK49oz3I92ODk7C+VK0/RVLofnBi2cAJXKCpT3jJr11Pf5H5Gw/DeffWFHfU//wDB9+L/+Uads+55kHMctlsA+ilysD7T1R2k221yW1cnnLs7acGr2x+4W2zXy/agT2ptV9hLAxiJ0WEOu8epy5R8L134p4H80CK/zhyL7Wtzfh+G1U2DZ1wquaKO51n/4Nz9yzetcBRuyn75slv79+3+wU65VrH0gG0M1NgzlQgr3vfd0GZ9w6cXnoO4zTz2Pv23gPHfdtf/Y4bM/LPf090E5lzS/PbQX30Pe/gj67oD9gWZhxeyx/Cz6gBNncNp+4YmnoExW/8R97KsuH2045rH9ttWOoMUMmP2ROs7maFWbMVqusz98Mvf52Se/uabv2QqtcZRWM2x/B5fb/wZQSv2sUuoZpdQzvOMFtzSuaz+27ZSKuPgKbmls2PfMz8/fsMYJdj025Huu9SVJcMthw76nuLJ8wxon2PXY2L6H/cFfcOtgx0Ppa61/X2v9oNb6QY+9rQoE14JtO9mc5D4VbAy2/fT3r4u1JBAQEdoOp5oJBNeDbT+5ru7r/0AgaAP2PexLquDWwVZojZNENGaV97T/bU3U63U6/vLxTrmwYFFtmA2qXvyHvhA1Oio50DmuREjLKIfsM7RCike1bj47VmuM5hXiJ8sFxpNPeBaflBFKXQe7M84oC9W64cQGjJqm6r1QZuwYalkUyqSHfVNmdMMlpiFIpQylRTn4gqwYBZQYDadatz/vsk/dnnm+Vh1pNuvAhuwnDEMqWvSb3ryh1On+QThXe0gRHd57AK8VmedwIqR/RVXsu/ryIl67Zv6SNdo3AHV7x26D8tht+6A8MrqnczwwgG32fUZfySO1bGzPkKkLcLzrrO8Ly0i3XFgw/ebF+ERDQ+vuxXYk0ubaK0X8C3A8gfYeaew737KP4gqjDze29DViw76Hg9PNXmtoVPFL89Llc53jiRNYt1JErv4j73wUyjmgZzMqDddZbrShNwcbsh9FRL5FHQ8tjm7E1gsVw7WmEeCcANofowflszjncxYVkYioaWkqohr6gJSPFKYuRmlKWWOYYbqPBbYGRhrLiYSZx/2MsrS8jD6BU/lHho2PdBnxbGAAadE+++35ianOccxnfZXHvslgkXq7zB/zuI1WqkybsjFsyvdEVhO8uOn/JtPKVVZKUPbTjDZsj7PmWhcsB4yqGFpreX0F14xYAv1+SGjXZUuG4Sg8N5PGP5xq9tvIohBySty1qIhEqNHhX7D5816pQ4ysOtYXXC9+Dd0Q13dukRK/IfsJWg1anjzfKXuWv/E9bNckm7ena7hfu+eo2QdFTN4w2IfzOlnjLDdbJ4l9VWXynpUl9AllZfq6wfYq9z7wBii3qvilcGHRXGswgT4taiINPBnn9mH6aiCLkou7DuBebX4Oh6BWM/OwXMb9FLE9dNxDHz8yZOZDK4Z7xDMvX6D1Yitr6beI6JBSar9SKkZEP0ZEj23heoJbC2I/gs1CbEewFYj9CDYLsR3BViD2I1gXNv3lTGsdKKV+jog+T6s68D/SWh+/zs8EAiIS+xFsHmI7gq1A7EewWYjtCLYCsR/BerEVWiNprT9HRJ9b7/kOESU965Oo9XV8H6Mxjg/ip/IBFhkuaVP1eKSyBn4arbdY9Cnr/FiSRXJk0Rp1hL/t6jHUEx6lKMaoJTwgkB31rMEipLUCfIZUDKkDXtpcO8HqAoU0DYdFkwmsz/88RUEmjVSaMovy1rIoPFx6YQfpiK4T/ehq2JD9aE1k0SqbVjShahUpPuOHUZ9drmD/2NENe/pYREUW1efQocNQfviND3aORwf3QF1XF+qaWiwCUMqijng8KBWjP9Uq+Cm9YT17Kolj1p3HT+cHD9wB5RMnXrFuhHSFRgPHu4tFRbMzDawUMZqaJux3TjtZXjb9XquyObjFGAsb9T1X+f3WGnCTwdvvMArTzMR5KL/41Fc6x60ajrmfwTGvseA7uR7je6+gEqm1Q33vZmzEfpRSkMrFDn/e3Yd09Arv2xBpw3ZKA8XGcHgI5/FQP177/JmzneM+D/3W0MgQlJ2AhWi31rwcow/2dqFkQLuMImlRBFNsvXAd9Fv9g0iPskNn86BOgUZf1MUiI49aazGLpE+ej33HI6ZFdqTHLNLcdWtrkVo36nvCKKSi5c/tlAEL80ibvzw5B2U3weibVsS6uIPPzFiO1GQhcqOWGasqizScZLR6YtGzS01D82o28UYH9h+C8m0Hkc6ftHRTnBJ4BUWQB8az/iHicch58XqRH68Bvod07PvS9kb23Yj9NCOHztfN2FRrZg7FFAsWErLI4kzOs3DRrN/PTl2GupNzSEXUDZzXdv8kmA6uxdJRcWlMImnaX6hhXz790mkoD/fiMzRgX8zmPPMJPqM+28N25OBBqBrfizbKKeUz0xfMZVg07Ew3RsUM2b4/FTdza6QP6ZQTLt7nWniVSAQEAoFAIBAIBAKB4LUNeTkTCAQCgUAgEAgEgl0AeTkTCAQCgUAgEAgEgl2ALWnONgqlNCWU4bJms+b2h0dR99CbRK6+HyHvs7xk9C5hhO+YNRYO3UHqLeXyhgfqMf1WgYWy9VgP9Vjc1BILQd2sY7lWR863zZ/OsDDJrSaGGHVCvLFvheUPQ7yux4RkDZbdPWYJh5wI+6ZRZgkyQ87lN8cB44evVIyOKNzhRK06iiiwwrAqi+ccjyHnd8VK0UBE1DuE2rC9d5owqgNjI1Dn+8xYGG+/FRg7PDmNeoHqOUx03HJQk/XKSy90jl9/FHVhb33o9VDmfPmipde4dHEK6mI+csBjMdRY9PUbDd6lCeR4xxJMc1hDGy4WTV96jNOdy+Fva0xvY2d04Gkn4nHWzzcYXGPwagMPV91i2sGpiYtQzlmh1VN51BjNLaPPW5zGsMKDY3tNgeX44LNevQZzgrmuQ10502d2uPiBAdSJzS2iT0iwdCoryyalxGAfalTjcezbZBJDNo+OGV1Z+or1A/16jHB+xWO2bgXXmrERfAbto23FrLnabKJP62MaEY9plRoN40+y3F80sB0llqy50TA+vrcPbTaZxvXRU6h78ZqmzfUK3ido8DDhO4typUJPfuMpq2yFpScc4xpLMVIP0Z78mCm7bN8TsqlXZ6lNQkuzlWYpVZIK+zPBbDG01rJKBfvvmRefg/LcAq5PB/bv7xz38ZDtKbQJzfYRdsj7iGnpFXv+rQiZNdvb2HEJ+Fp8rRD9241IEdWs/d2SY6UlCFHH3cs2qxmmH69XzB6iUMLfFvle1cH5ZI+Dy871+DceFouhYoXtz7D+evqFF6F8+DYMcX/7QbP2eDG0lfFx1JFVIpxLs9NmP1YssVRPTMv54FvvgfLz3/py57jG4gGUWtiOxQr2c4+dbsnFtbVeXv/6KF/OBAKBQCAQCAQCgWAXQF7OBAKBQCAQCAQCgWAXQF7OBAKBQCAQCAQCgWAX4IZqzjylqNtKTpC0+PhdadQN9eeQPxpGjANrHbse8qN5noVGxDiyFjfXYzzmkPHgtYvXmpszmoGwhW0qVVH3UQ2Rn59JWlqgBv7WZRoSnrfIjRuOeK2C+ruUjxojj/F663XTjloL+bMRU40UynjtQtX0XZlp+eot0zfNYHtzgXDoKKJG1egXMpbuI9eD2o0H7r0PymMHMA9LyeIQv3JuAuqKbAzLhQKUFwuG8z89gxqJHMtzRg7yuj/7V5/oHPs/gnb1tje9Gcq+jzY7NGRp4zRq6gpMM/Tt55DH7Vk5bNIs50/ANIbNMj6vbf79LNdgyOx7cQnb5ZDhZnuMD59nOY0E14etb+D+YX4JtSkXLlyCcsOqzyZQj1QtF6F88gXUkAxZ3P78EOYQ5DoPLsF4tWv7iFZtt8/KZ2ZrTpp19JeDLFdZKoHrWtw1a9VwP8uL2ELfs7iAOa+ylu6N52OMmuh/fY/lbXLMwNSqON48t5STwPW0YemhG030aXGmqSsX0RelM8YHhCwX5uIS+s+4jzoQ23Sa7L6lMubpcthDNIvmXs0m+lKu995phGFEhbLpQ20lJFNs/fViuO9JMS2Y65gy1xXWCfs3YH97L1nrZ43l/owrHPOMxnG188z5cbTpOtsznJ1AzerF6ZnOcT6Hfn9sD+rB+1newHy30fN4TO/qsr3btfRfbJm7Ml/jFX7MXDu6QnN247I5KgoorpY65eGU2bvkmV6xpxvH5bxmczFpninO1g9uZ600jr+d77bewLkYMjvjOsJY3LRzaAxzhI3sGYPyArOlmaKZN294w0NQtzQ7A+X3/9AjUP7cZz/fOX7qyW9A3d67HoDyO+95HZTPTp7rHJ//+regbqWJ+tcy2/sefb25dq2FPq6vD7We14J8ORMIBAKBQCAQCASCXQB5ORMIBAKBQCAQCASCXQB5ORMIBAKBQCAQCASCXYAbqzlzFfXnDecy6xsOcYLx3B0XObHJJPJpW1aeqyv5w6iFaQYsd4bFQY80y+/AdDTaQ153qWm42mGIba6GyD0NWLlk5QeZXELOt8/yw+RYPoTWjNHz1FZQm7C3D3NDDAwgj1tlTX6LxjJqU8plbMdKCTm/CyuG83thYgXqQouI3mB5drYbylEUt7jLLdfwfmvJDJx7voi6wee/9jSUlxaNXmFyahbqfJYzjo9LIzD2YWv5iIiG+3E6zc2wXFNWvqBSAXUfp86fx2sNYz4Y3zfXHrbyHRERjbDypRnU0b3ykikPDKPO5cIl1IlRC5/X1rKEHmoaEixHYNxjOXvq5vxcjukiPfytYD0wfkxrHIvJy5ehfP4SlifOGA59Xxbny54+1OBMX0K7fekZw7l/8O15qEsxDQnXL70WoIjIsTTBzYbxkSHTQgXcX9TRV3uWiLNYWII6xTRDmmm0JqenO8ddGdQ9pNg6VWygr7Y1NbEE05fwXI7smZSl4Y4CbFPkYjnONFO2pKpaw+vG4kyb4qNPSCWMMfG8iCtMC7xSwOfNJIxdKhfX6StsdocRaU01y4/avpxPGB3y3KhYVlZ/M9kQNVu4drfY7i6bMvO+VES7LLI8qw2W9ysWM/2fjTE9vItjUwlwnO18bI0FHKdCAbWD6Qzu84aHjdb64P4DUJfh608M29Fqmb5jyxppQpvgOdTs+cKlbLZ+Te+ww1OOopiV0+9A1mha92sc4C6Wu45WcA1I5U1/VWI4/pGP8/jB+1CTNWjlczx35gzUTVxCjaHjog/QVm7YBMuf9qY34H3msVn09Jef6By/8speqAtZXlVKY76xgpWHt9zC71BnWI7aSoT2UAnM+XMFtOdGAtfPQ/vQLvODxmbnWd7Ld77zTij/7qc+QmtBvpwJBAKBQCAQCAQCwS6AvJwJBAKBQCAQCAQCwS7ADaU1+p5LI/2GQpOLGSpcJoWfpBWjGxILOausz9AN9nmTh9XtzSKNIZ02n3+LK0jr6mL0q1Id23Fx0pxfbuCn0Bj7dD6awu71fIsiuIi0jIbGa/mMs9BlhVF++I4Hoa44zegwVfbbPvOZuVHFNpXL+H4e9/GT9NiQue/AwCDUzRbN5+rFUxjWdLvhOB6lUub+cwVjO2cmkMb38vFj+FsfnzlsmDGtlZDW6TJaUq2B9MNCyZRLFaRkXLh8AsrpJFKPjhw8YgoBUiK//tUnoLxv/34oHz5yuHPc24v2HGc0pa4c0j2cwFBJKg0c71oVP9nXChh+NwwtSkISbYOHzc6xMP1xi6rMw1lXWcqCGw97nK9HTdkAdUXzIv8H674szLy67t/KzPlRhDRiTk0rVZHidHnWUOhmZ5FOF4YY/n3PALbj5LcMLXhgCEMhH349hjfmS4pjhw3nEajZ42rWzUrvbHqO9UNDyPNYzDwjD8EdMFpao450se6kWf98Bx/Yc3B+1ZtsfbHSqTQbjLpfRD8WY/Qwm5amfLxuyGhoSRb+v2XN3WwOaa2JBFKplGLpZayQ960m1ilGY+TXIouW1mB+Kmyi8cQ8pBrlekzajxZLH1Os3FjfE2lNNYsK27AoVjzVBO8DPmXsORKxCcXLFbY+JZIWTZTbQAvbUWcphQJl5qJm94k5PJURa7T1FB5Le8SvVapim1dOmzV1YRH3atkEroN7RlHO0W2F4Y+x8P/cp0cB2ogdHZ2nJAgtSvlO0xojrajcNH6hyzX+o7WAYdonCkgvfPO9t0O5ZklyRplrTaRwHN6YR6r7Hf1GZlFlqQQWWDqN6gq2y1YKeU3cM+y7hHKOZAHHoaff+JvWMUzxwumTT72M+69XpqY6x3Xm4yYZ7X9ucR7KD93/RtPGPIb7/60//xSUmzXc+z77LWOns7Nnoe6BR3FMrgX5ciYQCAQCgUAgEAgEuwDyciYQCAQCgUAgEAgEuwDyciYQCAQCgUAgEAgEuwA3PJR+T9Zwf72m0V3FmS4oxcLsNmos3K+lucjnMYQm1wE0Q3wHbVkhZ1MZ5KpPzSM39exFDP06XzL3rbLo8fuSyKd+31vug/KeYXOvv332HNQ9dQZ5q0GEmnvhwX4AACAASURBVALPMc9UKiA/tlrGNmezLJxxaHjRiQTWxVgKg5TC+iA0D7l3bATqskuGP/zieWzTdsN1Pcr3GN7zmYlTnePpC8hbTvnYHysV5ECXi3OdY8VCBhdKyHkv1FC741nh/PsGUauTZNrG0fF7oTxm9fX5F56COlfheLdYGO35BROS9e67j0LdbYcwlOsYC5efeeP9neMXT16CukYdNQ4Nn4XSJ6MjizQa/MzMFJRjjHve1W33D2piajXUNNx4cDXHtc68hq7gClGIZkVWJtOHV2jMrtCg8fLapb3j41BOMf1fsWL1t8L7HpuYg3KSpTnwrJQRx5/8MtT1jqIOtXsP2qKy0pgoJirj/Ro52FfO+odoh6HIscLJa0tzkUyjlqWuWAjyNGo3Qiu8Mylc84YGsS+DRdYBlk41zcKIN5jf6hrqgfK1NJ59g+gvGmX0Ra61JvhcJ8a0PPUatiMeM/VODNfalQr66VYLfZ5rrT11pv0mFvo6ybRanqWxq7fweeYXdnat4tBaU9PSTyorxU7E1p/IuY6GKW7qtYvzOHLQP3tsd9eywuXHPOyvTBI1/9UmrnuB5bcazCwbLFVR3MEbu1bYes18XotpZwOWTsKedzNL6KemGhim/MxFXNv6LZ3UyAjqhjIsFUUizrR+lo6upZnmzFqbw2hnnZRHDvW7pm2jVl/mcvgMzy+jjmqZpdPYZ+mFf3gONe0+06z2nsZrxc+aNB5hhHNxnJmsH+I/OJathWx/2Xj621DuYtqwyErzEgZMKFdEW8m56F8aFfNMPUwWmdK4/yiytEejR43GP5tG23jo4CiU51bQv8yUja+tVlHffe70aVov5MuZQCAQCAQCgUAgEOwCyMuZQCAQCAQCgUAgEOwCyMuZQCAQCAQCgUAgEOwC3FjNmefRQE9vp1xbMrxmh/Hvy1XktdaajE+tDIm0yrjq/I2zxjjn+W6jx2iGyBk+dxl1NEuM16o9w812Gec7l8BzBzzM6ZBYMnzaQ7khqJvuwWvNFpBf3aiaZ3ju1CmocxgXt5VGvQl1WVoGxgfv6kJtX5ZxqOtWjhvdxJxf41bOuri/s+/5jUaFzp41+ZZOnj3TOZ6axlwSIctdlu1C3ceRQ+Od47uO3gV10/PIRb44j9fqHzJ9ue8g8razvahBm13G3+oFo427xPjx8wXkzx+9A4r07sNGZ1YpYxsjNDvSTbT3498w+rZDR1AHOTiKeYu+8fRXoDwza8ac5wuq1/A+y8to78mMuXbEclZVqtg3Nx7rt9cr8nNZ4JoyYvMn0jg4LUs3ZOeeIiJSV9yIa7TsKiTRd3f3QfnNb307lF96/mTn+MJ55NeHAbbxjIv618S40ZqGryBn/qUvfx3Kb/h+1C8lU0YHEPI8ZryMRQquoQu09Xg7LU1rBSFNzhv9hj3m6QbadYb5mjrL7ZWx9SPDqJWOp7AHXJTKUreVCzSfQh1EdgjHv8EEe6csfWg+j+tDg2ly60xM7VttbhWZD2gwjQizS9fKp1Uuo38ImOyUr8X9ebM29eSwr06XULPd2431djNyTBcYtVCrs9PQRBSskbMvZJqrOusjjwnH7DnkOeh/eZ5A32d59OztHtO6cSeXiTHtueUuI+Y6W+xaQYjtciyNq2Z7lZBpzEKXzWarmrtaxfXxLbx2ccrY9cXpC1AXj+H8SaVwH2Tnm4szP+1buWCbjZ3NmZdwHbo9a9qWtnK98Zysh/dgnrfSLNNWWgYyysY7FWO+h2mllLWu4egSNRxmEEwP61sD57Hx9x0WSyLL8uBZ+Q0DJnYM2YoxyObDO62ckk2FYxiOoL43ceEClKv26Uzbd+ftt0F5uIr3Hbb2SYcPYpyG2/pQF0f057QW5MuZQCAQCAQCgUAgEOwCyMuZQCAQCAQCgUAgEOwCyMuZQCAQCAQCgUAgEOwC3GDNmU/dfUaT0J2xcqA4yB8uFJEH36pg/hTHyjUREfJYNcuZlskgv7hFpnziHOq3Kg3UwiQSLK9LzFw7mUaecreL/PFnz8xCOWia3za6UHPW341tVIS6gFZg9HnVJpL1K1WW1y3Adihbc8d56Syvip3fg4jItzjvAdMXaEsjwPng241KuUjf+MrjnbI3eKRzfPDo3XBuson2cPSOQ1A+cthws8M64zg7rG9pAcqeb8bJdVGv1QrQViol5G13WbrJgOkrLs2hvScyk/hbS3Nx4OA4tpn9jaVWQB78yW8+b86tYd/c9d3fA+W778E8VbVnjObs7JkLUJdKIX+6K99LCDNHi2w+N3aYq39d2AKN66QWuiJ3maVyukInxXLBnT6DGq1azfiX249ivrp4HG3R4aIsC5HGcyPmyh9+5C1QvnTe2NNHfu8j2GamHbw0X4ByPGXs+hDTxr7y1Weg3M/ynN3+yEOd4yoxLRMTr8TY8y5Vjc6r0UTfY+vkmi2s225oralhaSWWlsy8TlUxH1QP0zf7bFwSGaODqFdRw1vmiTPZ8LuWX2+U8Jn7szgXXzmNuR8zCbNWZZKowWo00Od1D2OONBWatTmo4n0TbAdRqqOGKG7lj5qZRT03RdiOTBf603rN+IighdqUJMvPmU2jpmTJyvtWb+AYZTNc97Gz0FpTw7ILZdl5xDSqXMMasLGpWX7TZ7owl+UvjHtYr60cfIr7D6Yb00zIbDezGqKdNtn+y2F7iKb1vD7Pdch0Uy2Hafyt+zouS1alcFy59MnuyYj5mibLx1esMOG2rZtr4Ln2+NXYHN5uhK0GLU0ZfWUjsO7tYt9Vu9CukyxuQ/2E0eaHLj5vkMaJ7Ljox+KW/1OEe9WAjWnIbcnS6F2RFpSVvQFcP7IFM24sJSs196HOtDvAcUpb+TmDAtpseQ5zwFWnUDs9/cwLnePcnYehbnEGtXzNFPpLW0tbXcR9T9Hnir21IV/OBAKBQCAQCAQCgWAX4LovZ0qpP1JKzSmljln/1qOUelwpdbr9/+5rXUNw60LsR7BZiO0ItgKxH8FmIbYj2ArEfgRbxXpojR8lot8moj+x/u1DRPQFrfWHlVIfapd/+fqXUkQWfVH5/ppnxhNYlyIMUexZ75UO+57dYp/Z48kuKC/MmHC11QX87HigB7+dMkYEJSwq45GDo1DnsJMDF5/BpnZ5Ln5Wzcbw+Xq7D0L54KG9nePzl74FdSdPIQUu5jH6oTafe4OAfb72WJhYRpWw6Q4R49koi0ZxDWbYR2kb7KfVDGhuwlAM77/3+zrH8TiG7+5h7IfhEaSILhXM+E+cQephM0JqoqPw87/rmf4INaNTsb4NGSVFh+a3mS4Mfb1YRjqtw+whAroLD9+OxUwCn3d8ZKxznGChih1CKsDdd2F6gHzeUI0eq/0j1M1M49wZHcCwsaFFO/EZ1bhY5HSQE3QVfJS2zfcg7P7kEew5tUgzGg+whxgVb2ISUyR85nOfhXKxaOb9wwuYLuMdb3snlONxtEW7zTwwdxCykO5ZDP/7nve+p3N85hWkcv/TPzwO5SJLmXBy0oTW71ZIRUvU0fd+43+gjXi9hmrjDCJtrVJAH+gzKtV08XLneKWE59brxrbKa1OLPkrbYD+e59JAj+nPoG7mTDaDY6QDpK24HvZPMmn8LaeCVxm9tBkwmprFITx6BMM5z8wghb7Bwk739RsfGYRId4qIrbUZ9D3NqrEtN8lCbjMaWmUJx2nFoqZ25dAvlRkdP4ywXXFrf9BiVP3RvWNQ5mvTctGMEafs5XtwvVgDH6Vt8j1RFFHVslfP3q9EHj8ZirUKjmssZvqsZxBDpycZM89hfsu1bY+FMF9ZxlQutTLOqX37jYyg1EL7WF7GMY/HUe7RsimdxOmSbBIwZq9dz5QAFCN8BofJSoKWsYmQx/9nFFDN5CxRYaJzvDiJaRtIm9+2GD3SwkdpG+wnCENaLBua+UTF2FHA0jDEFEplUiy9ymLN7HuGXPRbSebHwyL2bcNKqUR9eN30YfRFdUYvLC8YW4pHzH8wqUxjHlNJUNy8v6o80jY9tnBHRdx/J++0KJIx/G1qjslXJnEPXThpUjVFl3AOZntwbV3K45xdnDHPPz13Ger2x4ZpvbjulzOt9VeIaIn983uJ6GPt448R0fvWfUfBLQWxH8FmIbYj2ArEfgSbhdiOYCsQ+xFsFZvVnA1qrafbxzNENLjWiUqpn1VKPaOUeqbExNOCWxbrsh/bdgL2l1PBLYtN+Z75+fm1ThPcWtiw72m1wqudIrj1sCnfEzZ3NmCN4FWDDfueaiC+51bFlgOC6FUO0Jqx+rTWv6+1flBr/WA2lVjrNMEtimvZj207nndDA4sKXgXYiO/p718XlUlwC2G9vsf33audIriFsRHf48bia50muEWxXt+T8sT33KrY7I53Vik1rLWeVkoNE9HcdX9Bq/zhWt1wV1XL5n3il5FKBTnPzRa+RwaOedErV5GnWmTl0TF8TB2Y+n19yIE9OIL8+2od60cP39s5jmn8Eri8wsL98tDii2aijQ0h97RQQc7zgdsx/HuuO2UdYwjuZcbTXV5hWg5Lv+RoXChaPGQuE7OElv6ERd0Hbc4GI+lv2H4cx6NUxoQs9a0bFgr483gPaluqAT6URf+nZDfyhzknmlhoaG2ZUr2F4eATSabnU6ghiRxTn+lFfVZMIwPCTaJWWMeM7UQK76tC1AA4LrbDt8JMJzOoMQwaaDuLk8iv7k2bl5r3/rPvhrpnXrgA5TLTzNQb5mtVo4Yc73wWx2gD2JTvuRLWuDL9wTLTX6ws49go19jIzDze/qlnnobys8dfgHJxyegHGizs+p133wXlgX7k9rvWuBZLaAOFAoa/H9+DepSRPQOd45/6l/8c6iYmz0L5my+8COVGxdje6cszUJcaws3D4rFjUK7+nTk++MgDULdcRturMu1YQ5ln4uHy7RDkrWD94YlpM75HKcpYaQ6OHjT632QK9TV87s1MTEM5CMxzpDMDUFco43riKpyrytJVlVaw7+bnMOUHizxPZOnKymXUhEQaT65WcS0qW1qOXAr9ZZPpfrRiOidLX5VjOshkCvvKYxvRbNZKW+JcO/T7+UsTUFaWljrGQrBvgcGzKd+jSVNoMz+stas7jhrOHEvPU2N9RNaa4pfRpyaYRnFgAO2rnjT92Qx4agK8r5vCdqUsvWA+jXuXoT4+N9l6a+0TqqxuZh7Xm1YF/Zhv2aYXsPkR4bxvtXBOeK55poiFf7fXYiIiqrE95NSFznFjGdtYLpvnDQKu/r0mNmw/gY5o2dqwzFTN3G0VcZ72DeIfIPUYjn/c2uvEizhPvSkWHr6M60vZUjmHGbQNf99eKHtMp5/Om2u1TqEmu9Vk4f6ZFjL71js6x9UC+jh65SSWmf3TtDm/ETG7GsL919Db3gjleNL4jKVTuD7mq+hPuvbhnvqSpf9NMo2/76NPvxY2++XsMSL6YPv4g0T06U1eR3BrQuxHsFmI7Qi2ArEfwWYhtiPYCsR+BOvGekLp/wURPUVER5RSl5VSP01EHyaidyulThPRu9plgeAKiP0INguxHcFWIPYj2CzEdgRbgdiPYKu4Lq1Ra/3ja1Q9us1tEbwGIfYj2CzEdgRbgdiPYLMQ2xFsBWI/gq3ihkZZ0KQptPiodv4gnlsomUBeayaLnOipecO3Pn8Z+bKej9eKzU5BuT5rzj80gBqzR9+OWq+zk6g3yY4aXm9fL+aVmGP86XyeaYEic68Y49DPzWOeBS+BHNn5gtEuTE6jZsD3sW/yOZYrpWZpw1jeHcWEZBHToDlWHifF8snxvCM7iVgsTsN7TQ4uuy31OmpVZoto1rE8andageH98lx7NabHaGl8Zs8z/OKA5QpJsTw+A704hnrJ2GyT5ZJSEc+HhPZvm0uk8bdhyMaMBTDQrrl2uYLcesU0AHE2xkXLppOpHqh765vugfIrZy9C+djLRp9UZvz4mH+jgwNpIjJaAbBzJjNcKSK3/atPfg3KF6dM7pKFIo7xMutfJ40c80TD+IS5RX6fr0J5fBxzOdl5zyaZz2s1UX9Rq2K7yiVTZinn6OjrD0D5+TMvQblZMhP9cgHnWooFO9jTheN6/plvd47dONqWM4L2tBKgzgGsWGM/Nqz8OHpDso+Nw1VEGUvzmU6ZMeR5Ibvy+EwsLRgtLxo94/ETmG8uYD4gznLz9KSNDnWK5eVZXEBbqgc4DkVbo8ZzPLH+KxQwf6EtjWw20M5SKfQ1Pb2YU9TOhdlgked0hAtIrc7yQpKt7UGf12D5kUK2biVTuPba8Dag+9gWaE1k6SK7LN1enmnKJqdRk1Nj86th7ZnUDPrb/b2oMRoYwzysJ6fMPkgzbXWqgn3flUb7eWnCaGczQ+jLM3GcA+dPvQzl0LLb/CFcMzIjmCOrchHzXbpWvrWcxrW5WkYfVy2hhCvmm/lTrKOdJvOoz+plE7VsaynZHIZ9kNpZ5xOLxWhszOiHnfNm3idxyChs4nyKKxyXZSuOw5MTmH9rpI7r1u2EF7fznNWY72l+G8e7xiIQqFFjh/XDuGeuBrh3vefgHVCuOGYMa5YOkIgotsLyCudwXjcvmbnUmkWb9QfQVqqDOHf8HuPHuh9FrXSB6YjzfWhbD2T2dY4f/xr60nh+/YHJthytUSAQCAQCgUAgEAgEW4e8nAkEAoFAIBAIBALBLoC8nAkEAoFAIBAIBALBLsAN1Zy5rkP5vOGQBp7hT5dZjhfdQg75Sglzd128ZLQwPG9LMoHvnNPnUScxmDDc1NHRfVCXH9kPZb/EOMUJw+Pdc+9DWDWDXNxkgLqQkMwzVir4vMMp5KI2Q7yvSpt+25PGHA3ZPPJ4S4uYi2hu1ugcWoyHXG8id58c5Aun41ZulBrTull6C6UYMXuboRWRVobb27I0W9US8qXjTK9VKqJusFk3z1wt4m999hjZNHL++7uNpiTXg7qG/jzeN/RQf1GLmzYv7cMxbITIYyaWQy20NAsR0wuEDrMVpjnL9xjOfxSy6zLtW1cXPkNMGXsolJiGroX2cN9RtMN81vTdZz/7j1A3P8tyluwwavUqHT9hdBOeZ2yX67WWWc6wQhl9z6VpM8+7BjCXYQ/rv94+nNfzZ804nziG2q7H/+lxKHfl8FqulQeqwfQFzQb6k//xeSz7lku0c54REaX60Cfce9/tUH7ua690jquEtnZqEXW2SZZzrzsw+poz33gW6gr9qGtZYnbsN019wOy0WjV2XCoy8cU2I+b7tGfI9Jmtb+rOYz5CV+Hc8/uwfqjf2MsXvvRlqIsiNm+zOM9nps2YDnZj3+W7UJ9WmMM+WZgza0K+G7WxaaaL7GL12bTxedku9GnpDNpOwPIZnjtjdFGuh/epMv1ak83DZsP0s+syrTSzw2QC/XRorXMtlvSt1dh0nrPNQWtyQtOGoYwZq9ll1L602Jh7LDecY9lX0EI9y74H7oTyMuujppUr1VUsJ2cO7anA1sWSpQeMmJ61UWdrCLvWhLU/q8xjDsl9ecx3OXIENWmFl6090yRq7JZnsVys4LVDK+/VSg37NdmNfjk7huXAyrlYr+EeybEE4IoL0rYZvu/R0Mhgp1yaNOtmqpuL4XAO+CyewPSC6Z+PvHAc6o70ov/4+QT68ZQ1/XQF1/2ll1BzttSPPuJcw+i9mkyPNnIY90F7u/G3zWmzvmSY1kuxPHdUwueNO2b9LNbYvufcOSjrKdwzL1t7l/QRljN0/0Eo12dwDey39K7334WayrH9eK1rQb6cCQQCgUAgEAgEAsEugLycCQQCgUAgEAgEAsEuwA2lNUZhQKWC+bTqNc2nc5+F98U4ykSei/9QtahG3Vn8BJtnYWBry0hrHBgx1JLRe94Gdccu46fSU2ew/PCwoXgUClg3ePBeKDuEn1KbDUNzzLP4xcU5/CSfbCIVY7jHum/IPl/fg9SZWgE//379c491ji9PINXSZaGgedxYKwo/tdi7vGPRRXgqhG0HC0fsWZ+0WfRuGuvCZ7j9AFInMlaaBpfZXYWFRq9XkdKWTJtnPnIIw2aP7cNP1o6PlNmyRZcbGx6GuiPnkd6S68GH6rGoRh6jB7GI1KTZ3EmkDZ0lYBQUxmIln4XSr1vhrHv7kPpQrqJ9VwpIDRjtN1SR933/d0Hdp/7+n+hGolIp05NPP9kp16zQ/mlG4XjPe94L5UDjfHv2pZOd464sm3sRUqZGBgah3Jo19KCVCvZf9fQrUO5moefTXaadGUbLSaTRn3Tl0Qi6rDQPuRyOYzKD4Yzf/s43QHllwcyBY8eQDhK2cK5dKjA6pZWqwptB2ystYznIsvQRSZMCY5JRWorW+DXrjN6yzdCkSVv+Om75TE63a1UwZHPcxf7RFm86ZKHzHQd98RV/OY2M79m3D+n3ff1oD3tYupW4Fe4814X27rI2zs0hPf/hNxj6/tAI0pACjeNdXMT1ZXnBUO8WC9g3novOp78PKU2R5dgili6kK4M2vLyCNDxtUbqaNWwjp3LvNDzXpZ6coSf2ZcxxYQkpUT0JtIE449nb9N6Bg0eg7sAwpt44fgnnaj5u1o2ghXNmYAjXSIf5+oqVgsfJ4vqzPI9+f98AroPVmLnXcog2sLSM9uIM74Xynjve2DmevHwS6uqMqubzuWbl+nEj3E81CrjezhPaT2CtbQ6b48wUdxShDmklNHPI08YX+x5u35tsPhUCpBgvWZu5QONviz763kmenslK39N0cP5ojbTPlQjH5fKcGfOcg/uaZbwtPTb5GJSPWGH4D7I9UW8cZRSVC+i3wpq5r522i4homdmdZnmhmhZNurWCEozmi6ehnGJUzYY1h/fdgVTj1hRSca8F+XImEAgEAoFAIBAIBLsA8nImEAgEAoFAIBAIBLsA8nImEAgEAoFAIBAIBLsAN1RzRkRk04JDKzS7Zlonh5AjGrIQxcsWhbhYRM6nZiF6hxnH/vXveEfneM+RN0Ld3/3xH0F5KI3ca7dpeLyT587iuQfugHKiF8NoprXhNVeXkPOcjFC70mR86oWSKef7UW/QOzQO5VoZQyE7VjGMIf9esXCrLcZFV4EhWCuNZOsgMOaz05qzbDpFb3vT6zrlA3cYfd/UJHKNR0dQC3b4EIY+Heo3YbFdjc9fYuHiGyykvd1fmTTaVSaDnGg3hoRq39LJ1SrIeX7gLtSnjR8eh3LL4sxr9jeVIGIccMa9d30zTq06jlPE9BeOx0JWJ6xrsboGC1HtuaiXCJumL/uZhuHNb3k9lP/6ExhGfrvRaDTp3AWjwViZMzz+Q/sPwbnJJI7r1BTO1YvnL3WOM2kc4yvshYV5rxWs/mZz77aDB6B8kIUkzlq6w7k51EJ29+DYDI/hM5SKpl0xnh2EhXDPsfu++3uMv1xi+t3Zy9g3Cw28eGrFnD+QQ7/kKbTF0SzO2/Sg0RRMXrgAdc2q8aU62lkRSLPZoksTlztle96XSqihsXU9RERNwjkSWikcUixMerOGc3GgH9eEuGNs6eCBUaxj93WYhiRmac6SSaZtY3aoa6i/aRTNOt3qQnvuHUZbcZjOZd+Y0R/FE2g7xQr62lgMtyOeFe49YL7GTitBRBSyNd+1dKQ6QE1MJo12ttOI+S7tGzL3fP/3vrNzfPHcOJxbqqNWsMH0lEHD2Mj4COqzNBMf6z7U5KxYa3ulivfZ04fpNQKmiS9bqX80S1uQ0SydBJuPg1Z6kcocrnvlSfSXLeY/0oPGfkbufAvURS30gXNTuB+rli07Zm3KpdF+PEK7tSVZrSr+1t6r7vS+R5GmmDUWnrUP6GMa1aaL/sNje7lq3VxnlGtU96NecbLM0pNYzxljukgVMO1bhPNtuNdohz0m9ywyvaJeQnuYWjT+dSWFPm5vA32Cs4D7QLL8qRM4rAr9djXEvtKWNi7F0jBMT16GcoqlkaoE5r75Bj5w3z2Hab2QL2cCgUAgEAgEAoFAsAsgL2cCgUAgEAgEAoFAsAsgL2cCgUAgEAgEAoFAsAtwQzVniohsmUFo8cgVy6/E5C2ka8gvVRY1uacXczIMpZDn+cCDyPM8+rDRmS3PsXwwAfKYD+zBnB2RdeOhAeTt8hxSVZYHrWlxUVs17PqQUJNzlvFaXzr2TOf44TfidXuHeqFcLKEOxE5Z0TeOWpSI9XvYZLoyi8u/Ms/0WCVz4Yhx1LcbqVSSXnfP7Z3ynfcbzVntLtSUpbtQ28Jbpi2OsMN0Uj1p5OlrZod2MYrwygHPn8N0Eo2GpRm5DfUCyRiOS62Cdqgdy14U2o5m2p2I8eBD63kjpkto1pBbHkbYDsez+or9Lae0iPzwi+cnoPzIm+/vHFdbqGNJJZCnvdOIwpAqK6ZPq3Xz3PEUagVXStj3FycuQDlv2VdYYRrOOvLtp2fOYHnK5ExRDp77Iz/0fmxzeQnKX/zaE6ZNLyK/vrcL+fgzp7F/Ry19ykoLcyuRj/6ipxdzs9195K7OcfN9aHt/9Icfh3KthP0xVbD8K8vP12gyXcsC5nocsfo5xnRSfQMmL9PCHHuebUYURVStmbGKLM1JM0B/2dOPeqaI6UHrdeMTxsZQ5/HyMcxz53s4hsNDZr3pZ3o0V2Ff+ix9ZSxuxi3F7J3nOaMa+sBa0WjFlubRVrSD451k89q+Vy6LvqdYRfvWIfrLpJWPUjHb4droXBL3AKHVdzmmVfFZHsidhqs05VzTT296wMzFh+5E7WCpij6hxRagVmDlqqoyPSvzPfubeO1qw9hquYK/9X2c18tF1Acm9ps+rDXwPjrfB+XJGcxJeNrS6N7Rjdq2S/NoA8T0r2HC6DIz+x6AurccHIfy0gRqzl759rOd47kZnFtptQxlaqAGqR6adii2znuWATWZzW43nMihZM3Y9lRgNJ4DbO5113B/5s3hOAQl88xH78C4BXuPoO566QXsr2E75oOP89hnNposs3yGVh6wVAq1sKfOXoByXwWvdWDc+NPLMezr2TP4fMkSAjG0lQAAIABJREFU2pKy5ooK0a7qTJ/XZPvgZsXUL4Vs75LC/WWpifOh0jD3XZrEtcnbi771WpAvZwKBQCAQCAQCgUCwCyAvZwKBQCAQCAQCgUCwCyAvZwKBQCAQCAQCgUCwC3BDNWdaE0UWR79m5bSIsXxinoekeddBjvltQ4Zzn0jiO+b4PuTy3/vmd0B5+Mg9nePnn/pjqNs7hlz+oTvvhnKs3+ibvBTmeKmyHCW1InJVZ6eMJmd5FjVlIcuPlMyiLqCvz/THxNRzUDc4jNzygOUw0ZZeQlWQax1qlt+D6ZeSVn6c2BCOSTFu6ZF22JIcx6GklV8oY+VaSafYzVkOHCazImVrzliOCq6di1qsbOm5uE4yYOo2lj6ItDLnZ/KoTQlC/G3IuPcUWblVCHUuPE8RhVi2cytpYp0RsLx2LB9M3GqHH+LzpuvYRj2LtjR/zvCt9xxB7eaCgza604h0RE1L81e1NAZnzqMu7JOf+gSUv/blL0NZWbnxZov4HPMXUXfnM8Fjy+rf2BD6j69/5atQbhQXoPzy6VOd48oscuYL8zhu+V70H/Mz5vziCmoCuvOoA2iGp6D8xBPf7hwnc6hv7Wb5kRZaqBurWnleJpkeTceZPom1y7X0Tfle7CvXNXP+7OlztJNQSoE21c49Fb9CR4f6g3gC54xj+ZOwifOltIyakWoZdT/795q1J8n6LpPCnGld3TimrcDoNUKW08d1sY19fXituTnTzmmmEXr22ItQvo1paefmzTNMTWOOq4Cwr/I5vK9v+dN4HO05YD6+UUfbstwlpXryUFcs32DfEwRUXjLr7uXzxzrHe0ZR+zM6jHpPj41rZOmNiwvoHwoFXNt7e3CuVizdfrWGNlBhOqFSGefbESsHY6XC9FlMt9yfxDxovpWP6nVveBjqlqqoI7owg3rfppVvKqzhGFM3av5H7sG+7L/n3Z3jYBm1P0snvgnl88e+BeWFs8YHOjF8Xsczdqm4znybEUaaViqmj55YMfcLcHjpkQjHNDmHOcQS1h7z/te9E+pGxjAn72eefgnKKw3T96GHY9ZiOYiTLHds/bJph9uD+54D3ahXrIc4/l7a+Nd73vwQ1C2h+6ClZ1EP27A2fpGHNlljbUynWWdauU5rMbaf7MV3hDph/YzlI1cKOEeXT56m9UK+nAkEAoFAIBAIBALBLoC8nAkEAoFAIBAIBALBLsCNDaWvFPkWHWW5ZD6zhnX8zJhkITddB+lYA1b4/IlppIMcfOB7oLznbiwTmc+SrRJ+su7K4uf8/sP3Qbnimc+yx5/DT+GNGl6rWMR2LUyakLIuo5YkEjgUo/uRqnjPYfPZOXAx3LnvIm3DZyFHPYvyUb2IIbgjFgo6YK/rZdd8sk314n0HR8ynYN/f2fd813Up22X6Xls0o2oD+1KzUL+NxtoUjiYLydxoYN8FAfLSWlZ4fB7OuVpFamq1grTWwArJm+1BO8t24Rjms/i5PxEzn/dDRl8ghdQKh7CctSiyi3P423oNKT5RhJ/sFZn7RiH2ay6LVIF9e5GSU6uaftYspHhXFm1pp+F6LnVZfd6yzLXI6GMvP/88lGfPn4eyY7nNFKNfxxykuekm9rdjhWHfw+jIPVns+2UWKvvA+JHO8cUQKUyFJaQThnG0p1kr5H+1inO+sISUH+WysMNW2OlCFcNVOzH005HLnt+ihFQZ7TdkcyvNrpXpMv3BqXeRDq26nY2N7ns+DfWZEMhxy9el4vi8yRSuYwHz875FtcklcE4cHMX5k2dr4IiVPiATx2fOpZH2V3fwt7HItLO4gvdNpPFcP4U2PTNvfMTEEvq4V86g7czMIfWsuGJ+22qhr7nj6DCUMwm8b2iHlWc0b83ShSRi7LfWuqZcXFuDcGepaByu41LeokmVFg3Na5qFae8bQvvpYm1PZ6153YWUR1fh2pXFYaWujDlfMz8VsLXsxMsnodzfbyiEqRRSV6uMEnnvOPq1tz1oQuDXAhy3KhuKQ2Pom2YXjQ+cmkFK7QxL3XIpxGvXLUpoMo+0+vxduCe878iboDx63tB1X3zyc1A3P2PWA61wPmw3dNiiZnGqUz6zaOZbrYVjmN+De4Z7fWYPnuns/SyNRy6DdMMG81uNqinHfByjusZz+RoYa5r71pZwDB0P7TtycQxnrbmyfOJlqEsl0CeUEiiNKlnpNRoZnCucmpvqw+dfaho/VmJ7ZKeF6/L0DPo1J2HmepHNq3QRaZvXgnw5EwgEAoFAIBAIBIJdAHk5EwgEAoFAIBAIBIJdAHk5EwgEAoFAIBAIBIJdgBsbSj+KqGGFQ03Fze0V44/6DpKRNeOJJzPm/B/40R+Auoe/91Eo5/qQyz977kTn2GX3KZSQEzp/4RUoT5UM//SJT30K6jJJ5L3XG8hFHRo0mpcc09ycv4z86SZrV8/IeOf48N2vgzoKUfuzVMAw/VVLz7dcw+sqjSZQryEHvmxx+3UZ9QRHLfo7D1e/3SgUivSpx/6hUw59E3Z8mYXJLa9g+FImVwQN2uws/jZkD9LTj6HCu/uMzi7O9ACVJdQYnjp9Asp2COex/fugzvXRdnJZDO26f7/h+e8ZG8K6A0y7xMJsZy0tR9SVgzpiep0Wm2euZ/5+47LrDo4zXVwO7bBl64KQhk49PawdOwzXdSljac48a/41F5F/vnAK5+JYBvWByuLUl1h45zqbtyqJWqC4FXZ4fpaFJf/mC1AezCJPftEKtb7CwleXWcj+2gLq6MjSunlsMJI+02owndx8wdw3dNBeUh4KW3h6CQf8OmukRk1EpYLPVCyacncvauggVjqxVBLbDK2ItPVcCUvL4Hv4vH4cy/US6jRbLTMnurI4B+67D+cTHxffN+PmsRD+IdMukYN2GY8ZX5XJMJ0km9c6Qr/mW8/+8klcDyssFDqFOJdsDW/Mxfs6DvoLzdOaOKaviszeS1V8Pm7TTUvnEjTw3CbTJO80fNelYcv3qKbpk6VZDP/9wouY1uO5Y9jfg6NGK/SWt70V6kb70U/Vl1EP5dpzlemCPKb92TuC+tektYbEY2jjuVgKypTFa7dCc61SDe2lxtK+nDh9AcrLDZN+4YEDGDq/PIBtPj+NoeNPXDS6uRfOYb+WmCa3L4fPcMegWVMffOu7oe65px7vHF88g/a+3cjFHfqufWatml8yuqpvncfxffwC7l2TB3CPmcqY+ZZ18XlbLM1JqFBnVbHmUILte0KmBybF9MGW/1iqsDRPdVwvYxVsR6tg1iJ99hLUpdi3pWYK/elLgZnnFxZwniWYu4xF6F98KwaEarHUAAVctysa12nP8q+hj7/d183WsWtAvpwJBAKBQCAQCAQCwS6AvJwJBAKBQCAQCAQCwS7AdV/OlFJjSqkvKaVeVkodV0r9Qvvfe5RSjyulTrf/3329awluLYjtCLYCsR/BZiG2I9gKxH4Em4XYjmA7sB7NWUBEv6i1/rZSKktEzyqlHieinyKiL2itP6yU+hARfYiIfvlaF9KkKbJzIkRWLhKW8yZgegSlWF6TuOGX3vc61GDFmX7n5eefg/LylMnV02B89NIy8kknzmBuhbI2vG0/xN9mPJZ7JoGc3/5uwwmfnkV+dNDC562WkJs7cd7m2x7HNpUxn1bCw74K4kY3tRggLzfJNDEplhwl6RmecqmKOpbAyl21huRs22ynWCrT4196slPO7zE5n3SIffXck1+C8r49mOOkr9fouSYvs3GIkGud6kGOcNMxdjrLdIKPPoS5Uu67504oVy1bc3zGl790EcqnTmM+qZeOGRvOd2E+jx/64R+E8iN3HoZyTJu/wewZxvwmTaY5Uw7TfViawxaxfB8eluN5tKWkxTWPXJbvidaF7fM9iiiytBLa0jrEGGfeb+Fz7c1hDpTA0l2VmBbGzeHYODHsk9qs0QU0CqgZKC3iPF6IsF2Fhjl//IF7oG5mHvOcFZZRf5DJGF9Ur6JOouWzHFkN1AHUWsbmHWYfCfZ8muVaCi2dmct0LQ7LeRQx3dTcvNG6sVQz5MWUVccEBO1/pu2ynYio2TJ9UqqYcXCyqN2oFXAMWwH2Rypp9Aku0/0UFnHMGkxztlI2tmbreIiINBsz38Nx8i2brbJ8hWxaU7OG9bY2fGZmGtuocfwbLj5vzNLGuUxXzvPtBUzrGLdyO67UcZ7NLGKeP00s1502z6+YfiYZX5fUftvsp1at0ItWTlS9aHx9Vy/qqJ49jvnFTjIN1iPvMHr6P/2zj0Pd9z/6Zih3J9ieybI9z2d2W0df1N+LWusobvzH8nU0e4r505b1DUAxX3PmIurj/8tv/hcoL8yZ/dgb3ojP954P/ASUB4awL9OBsZmRAOfD8QL6jIhphees9fgQy9954MgdneOZy6hla2PbbCfhKzo8Yuz1X1g55sbimLP2i6/gPugLF3Au3rdvpHNcPou5OwvsO43LfHGhaeyjP4Uaq1Az3XqE953X5loLKVwf6x72e1axvH5WLr+oiefSIu5H43Hcb1+2fMYiy4E3xN4RUmlsVzZtrqWZrnyhib7Ic5m208oFeZdGH58pMY3uNXDdL2da62mt9bfbxyUiOkFEo0T0XiL6WPu0jxHR+9Z9V8EtAbEdwVYg9iPYLMR2BFuB2I9gsxDbEWwHNqQ5U0qNE9H9RPRNIhrUWn/nz2gzRDS4xm9+Vin1jFLqmUqtebVTBLcAtmo7zeaNjbAl2F3Yqv1Uy7WrnSK4BbBV26k31//XTsFrD1u1n0ZL7OdWxVZtZ74aXO0UwS2Adb+cKaUyRPQJIvrXWmv4nqi11rQGs01r/fta6we11g+mk7GrnSJ4jWM7bCcWi1/tFMEtgO2wn1QmebVTBK9xbIftJGLrJOEKXnPYDvvhMgvBrYHtsJ3+1A3NdiXYRVjXyCulfFo1sj/TWv9d+59nlVLDWutppdQwEc2tfYXvQJOd6yYKzJc0zoEOmcigSfgXhMEuw7n//GOfhbqeQdRkDXCdTdVw+30fN/2ZNGqyPJbXJ2052qEBzEVVKyEPPunitRfnTf6tVhOfL5vAzWOzjPzh08890zmePnkK6hoB+yrgY5vt3ETpPcjLpTR+zXTiyK9NWLqybsI2Hr1zf+c4mThHV8N22U53Ty994Md/slOODxzqHFdLqBs7/RLmixoewvF3LC1UMoHj3WT5Lg7fdQjK3cOGi1/tQ93He773XVDm+j07V0iEFHgKNHK86wGOw5zFvb94fgrvw/J7zFxG/dGF46c7x04dr3tuBrv+oe96EMr7xg1PnedAcxLsjy0+2rSybIeY7iOmrqoTugLbZT9hGFHB0gM1qsbu002cL/1DI1BevIiXP3PB6BHmW9ifPT2oT3PYvK5ExkeELH9KUMWvw/UG0+RYutv5GczlVykj7123cN1PxY1/bTIOvYqjnwrq2I6Yzb9n+q56A/1HxJIKNi0fH/fRXmIJ5nuZHiFplVvseew5vJbgdbtsJwgDWrByzI1Yft/WnxERBRGzh160h1LRnB8E+NsG01zx3JEnzxidiMPmD9dN7h1HG3asHEf1CtpVyO4bME1F3Lo21zKemkSt7P7+YSj3ZK3cgiy3YaWCX5SWA7y2Z+Vm4/kEl1k50vj8ytra+Ar9VqW6PhbGdtlPK4xo3tKXnvRN7i53Dn31pWnU9L310bdD+Vd+9d91jv+/3/4dqPv7zzwG5dtHcX/ix6x9AMuxF4ZoEz1daLf9PeYjD8+JFovhvHaYbqhsrRtNlhfwd3/vj6H88smXoGz7jE8+9jdQt+fI3VC++xBqrZNxo2/LabSBEXQ1FLB2VSxNsmasnX2jRvf1jH/1Dw7bZTuRjqhh6b16EqZdbzqMeREXKugTnp3E+XRi1qw9h5iGsxnDMdNM71yy1gTdwGe2c4Kt/pY5LqtsjwkRUUnjPC4yfV/vnbd3jl22ZXjp81+G8hhbt/Z0WxpEtk4lPLzYSgv7o7Jo+nyIrUsjfTivYg7LC7lk+n0fix0xlt/GPGdKKUVEf0hEJ7TWv2lVPUZEH2wff5CIPr3uuwpuCYjtCLYCsR/BZiG2I9gKxH4Em4XYjmA7sJ4vZ48Q0U8Q0UtKqefb//YrRPRhIvprpdRPE9FFIvqRnWmi4FUMsR3BViD2I9gsxHYEW4HYj2CzENsRbBnXfTnTWn+NiNQa1Y+u8e9rXExRZPG5Ylboef6ZkVjIZu0iHS+yRNoLC0hrK89jOdnCkJuRFXa3pxs/UeZHMBxrwMIOT06Za2viVBvszmaAn9JdZSiR6QTSOFkmAXL5P1iUprCJn6sdxpErVpFe2YybT7bZEXyeSrIA5VKEn3/rFfNxtTd3AOr6LHqP519pSttpO0oRxa1Q6KdOHuscF1dwvLXGcWkx2k65bEKJr/6RyyARR31Aq4qhsVfmzbVnL2Eo/X/4/D9AebnEfls245bNIa2kqxtpJOkcUr4uXzZUxoG+UWxzDsMef/XvsR1Lp1/sHIcsuMGZmVm8TwXbfOiooXV25dBmu6zUEEREyRRSFrrSpi99FkY7lbq+hnBbfU+kiGrW2FrTIFBI06iwqNzTCv9h2pqb5Sabpywcuusjda1qhSjWbN7WmL/QmlFBLQrN5DzSGnk4ecW6bX7Z8gnM5jWjNPlJpGLmLNoSp5vzueYyelDSSprg8JQFjBKkGD1KW33Fw3MDdUpdaSLbaTvNVosmpsz88y3aOKcAjo0NQZlT6Iplm9bI+o5R6KsB+q0TZwx1nNPtpyaQDtfXg5Trri5Dpzl9GsN/83XsB74PU4LEtfFV3XkMo50soj9ZLOB6Elnzw2d0+2IZ/UmlgSkeqlbfOkxzXG8xe3dx/bHTMiyXcU72Za+vP91O+4nF4zQ6flunHJLxsS1Gi46xkN7DY+jrtbUPGBvBFDH/9OlPQLk0gzaQSpo+jCd5H+Cjxj1cB23KcSqJ4xZj8zgRw2tri748X8P15fgJTFX0rndh1957372d4z/4CFIgn/oKrnMHhpAyFksZe1uYwT3CC6dRGuKnsc2DOXOtsMZSMVj7kKsZyLbue0iBbavA+JNhlrrm4f24HhebaFsXLGpt1cXmDYyh9MON4RjXLV9VZ/sar8XXKexLu1XB7DzU5ZhUolHE9XLJmuf5brTnvGLrCUsHMWrR8WOMJKjS6E+Uj+8XTtn43kEP+yLBRtZh8oOq1T9dLMz+wb04ZtfChqI1CgQCgUAgEAgEAoFgZyAvZwKBQCAQCAQCgUCwCyAvZwKBQCAQCAQCgUCwC3CDkygocpTheibihpuqWaj8NOM1p7MYNrRqcbV7s8h59ti1miuoq4kcc37VR+764OB+PJfplY7cY3jeT37pC3gfjfxSn2khapbeIMdC2cZYeFqXhUouWyHQz0+jpqxQYLxdhdz9/sPmHXw0z0L2a+y75QV8hljd0smx0Ly1quHaRuuLjL5pREGLSouGN/7FT/9953hi5jKc67CwqC++iJpDW6MSMJ0PsX5//LNfhHLMSr1w3/0PQF0zhnqMYgP78twlEzl3cfEE/raO952auQDl8xfM+Q/e/zqo+/n//d9A+elvPAXlYMWEay42UANTY3qTc8+gju6rzxotS9pDfYkdmpmIyGUh2bOW5mzPvnGoe+8P/RjdSCilyLM0ny1LK1WuYZ8sFdFellgo5cDSV+oA+6DOw9SzEL4tK2WCw9N0dKFPcF3Wv5aPYJHDr9R+8d9aZYfpeR12rYj9g2P91mXa4DBiGjR+bbgv4/1zrRjTEETWtfk0hXmr14ilv03QRBRY91hcMRqmHNNZFllKA5f5dVvvXKnhuXwcNEvrkU2a384t4W+ffwlD2qeTqO1o1O25y8LwMz3oidN4rcGUWXvtOU1ENDSE6/LiRdT2KM+M8dw8tmnPHlxPQqbBbFg6lyrTwgbs3JD3Vc5opJostHeF60R3GJo0BWRsObTaE4uzfQ66gCvsaXbO9OHCEu4DLs9gWH4doL+291stphPiMyjONORpS4vtemgvyQTOgQTT00eWvunSPO7FSOM4vu8HfxDKDz/8cOd4YgLX+U8+9hkoP/fCPiiHdeN7l2dRd9hcnISyF+LaXQ1MCPRzy7gmpuJmz9RosDRG2wxNRNrqI235xFiE69IdPThm88OoX6xYa3/A1qm+Xoy1kMigfq1g2WyL6dYDVm64eG3H0mznmI/jCqxmEceJrH2vZml/9jBZn+/iIpGtmWsNuLjvXS7gvIpnUc8WtUxDgyrqaPm+jknOKLK0s8N3YDyA/Xuxn68F+XImEAgEAoFAIBAIBLsA8nImEAgEAoFAIBAIBLsA8nImEAgEAoFAIBAIBLsAN1Rz5iiimJUHp2pxYN0Ey2Pmon6lynRErm84sHGWV+P/b+9cYyS5rjp+blf1c2Z63jOeXe96117bOI5jrDgmCRHBQVEARSIfEIJPQULiK4gvIL4hgcQniAQSKFKQjEAyESAlSkBKgJCQGJL4kfixTtZre9f7mtmd9/S7u+ryYSdzz/n3dPdkdma2d/f/kyz33equunXr3HOrps7/nCzULMiVbPzseDlsX4QY6NpxWztk7sQZ075yPdQXevxDP2+2VW5cNe13zr1h2tVKiF2NI3s+46A3caALuHYl7Pu9i1DnLG/PtzxvY75np8K+XQM0Mav2t5Nr1iSOz4X6W/dP2LE5fzboC5p1G3d80GSzOVmYX9hpP3wqaAM9jFWcse3IoQ4m2KAHPUIO7FCyNir62LFQd+YXP/Ups22sBHXACjaO+ezrP9z5fO7822bbfcdPmXYDREWR0mC+fu5Hdr/nbM2W0qnHTPvq1dCPyQnbpzmoLVUatXNpdTHoT1au2PpIN5bt3GkkUF9O6UKurVu7+ugv9SoDczikSSKVraAj2NwMceHVip2L1SrMEehqeSLMp3yxf702B0KiYhzGOwu1m1AnlgXdh9YvJSDyRM0Zqkj05gjFTc5+N4G6Z1rf1VVDEMRgiWDds3BOMeivcF8F0K5o3YsHbVte6Ru7tGsHTBzFMjkdtFVltX4U4BqtblptVBG00+1WOI8W1IyLs/a65PJ2braS4GOvr9rjNDr2t1NjtubT/Q+G/rfb9pptbllNxYXLVhuWm1W16rz97WgJatXNWf9SLoa5Ulm3Ws4LFy+Y9kOPnDTtltLatBI7J8Hld2nSTqo1r1iwfWzWrQ70sOl0ElleD3qwdiecSwxz0YNNvPLq66b9xJMfVNteM9va8Lf2Vgz68naYi9eu2TqJjSbUW4O5qkvU4WzL5qwOEf1WonS2lYb1tVMz86Y9M211iFtK/3vfgq0huLpm7fRrX/s3026oeqYrKxWzrQr61hj8eKRsb3Le6oTm5kM/OuArDx4nqeprojSrAprC8dhemadOgB50a3Xnc2vJ1kVsV22eghzUfWuoPrTh3iST2n4koGd0idL4w7i3smhN1r84NR+SyM5jrIWcYJ1Qda9bSKyN+rb1AYsF6wPbyvemsMRnQXdbq9l95ZS9z560NluI4Rz6wDdnhBBCCCGEEDIE8OGMEEIIIYQQQoYAPpwRQgghhBBCyBBwpJqzOHYyP6tiV1dCHHY9sUHkEAIrPgPx+Somuly2ccq5rI0JrVdtrHtRx0S37BC8+MILpv3go1ZXc/ly0FlhvaBS3h43At1csRi0Cqhzqddtu9OxcayjKib6o089YrYVoGZaB+o9JO1Ql6F+CWpQbFmdx1zJ1vt46pHHw7YJGx/+0rV3wzFBx3DQdDodWb0RYqY//HOh/slHP/5x89183mp34ghipFWcf+pBnyb2t1ojIiJSb4WxXLn8rtm22rCx16vLq6b9jtKZXb1u6wGNzh0zbcnb6+JyQbvS6tj6Jl//5rdN+4GHnjDtE1NBJ1fIWHsvZa2NNhtWu/HOZtBNjoKdJaA/WVyzcf0zM6d2Ptfadpz/65vfk6Ok0+nIsvI3+ro2GnautaC2YbYAmgqlYcF5m+myNWtPotoeavx0EjuemRj0aiWls+oqigW6sT6FB1Gj5bpUJJZaLdg86tFi0JdgnTPdTzxut04O+qE2FwpWA6E1Z1g/7aBJ0lS21BikSmNxbN7WscmBxqwGde5GSkr/G4M2I7Ljkc3Za+iUrqxWt7/NFa2/GJ22NY7amWBbndjaWWEC6lLF1t63VK2thx+0taQ6i3bOd6p2PmxUgg98+MzDZtvlS2/ZPoLeyqnbk8qmrS2Uwt+VR0Hvq7Vw1SrUnoM17rDxzkui6mc6pZ2p1Gzf6hU7nos3bO2yz/3VX+98vnje1qOrwFp1/orVZGl9Nc7jNtx/ucSuMZEab/QXDmzRO9ANmY3Wxosj9jgrK/Z880oTvblh7+OaTXucCxdsHTStV4LlRzzUYkNPlMuG447k7VyqVXV918OtsegyGcmp+8ZI9bu1bm0FtV7HYF4/sRHu/d5ct/e1i1ffM+3Nuh3rilpPGuBvszAGHW/7kfFhHldhDajBGhjDvE6bqfoMWnBYawT60VD+NQU9WhW/m7d2KOp5owD3SGkCPh3qzZ2ZD/5lMmePU1ux2rZ+8M0ZIYQQQgghhAwBfDgjhBBCCCGEkCHgSMMaczknJ0+E18XjLoRinL9kX+8v3bCvA1uJfbU4OqpeldZsavkkta97I3gGXVWhAlsV+7qz0bb7irxtj42GVMFLizZs7TKk4E7hle38bAi/dJB+dG19zbTzI/Z8J8bDq9IchE41IZxBICyl2gzfb1XstpHU7uvMCZv689h9oc+XLttX4Ss3wjXrdHqHUR0EmYyTERXWtbIZxvqVV18y352DdM7zczalbLsdxn5tDV4zQ6mBGK7T8dMh/PDEpA2PuXLOpqetVuzrbp2CtzRtU11HBRsyWKvbfiwshDTTi1dt+MbyirXRhWM2JtipUJJKE0oexNbO2piyXIVU5CEkobViw2YkY21rXpUHaEF4V1dE2yGTei9tnT5XpQOOYb7kIXVuvmhD6nRhkd1BAAAVPklEQVScjgMPiunwMeolUT4BQ4siCIGMcradUanWc9BnDBHEfXeHEKo+gvvAMMGJiWCreu6IiDQhBDSBtPw6lBH70IFQkw6khpZEt3ufX5Icsu+JMlIaCSFCiQo5b8J4xFksh2BTJ1v7gBBYe0klzvY+ryb4JRfb45bG7XG3tkK4chHs+cYNu47FsfVrk8XQz9KE9VOjBRvGOD9ry9Ys+7CulUr2BOfmeqdNFxHRyxpGMJXHrf8cK9tz2twIfn152aaN9xkbpnbYxHEsU9NT6l/CtapXrK9ujti+ZSD1+Lpar6ZnbUjt+JRN+d4B55P6YLedtl2bMA15G0Lk0nbvkMgm+PYUfY2SDmTA5tfhmn/nhe+Y9rPPPrvz+Y2zb9o+g99qwflqiUIK44hhnAmui62wr0sXL9n95sP8aLcOt4SQiJhQeOfCHIJKCdLI2L5kIaTu5ELwYe9ehlD+prXDJLXb15XPW4ZFbwzWPOd7rwEb4NIW4d4V7T3yvUPu8c1SFiQpS8pHbog9TgX6cRwczISy/wjKlszHNoT8g3DP/NCJcGFKdfss0kz2XsaDb84IIYQQQgghZAjgwxkhhBBCCCGEDAF8OCOEEEIIIYSQIeBINWdR7KQ8GWJm60qzNDkHKadHbBrQ5SUbI91QWoc4Z+PgQQYhaRvTxoZ9bdSt1mukaAUnjZrV/tQbIX69BfvFVKbe23PS6YDLECNfLttY/XrdavCWV0I/R0dHzDZMq+06NuY3p4KTIUO75EDXcurMKduPWtjXt7511mx79dz18L3G4abSzziRvNJgNBsh9v6FF/7TfNe37TUrl+xYt1Xa/wakQsdUrg+cOmHa7//w+3Y+P3TSpr9fv2S1YItrVuuQU7b10LSNU75xw8YmP/Ho+0378Sce3fn8/D/8PfTZ6kvaoH1stULbQ7pqKdjrFoHg6tTpB3c+X7/0Y/tb0EgVQSf52GOh5EOjZs/vxILVSxw2cRzL9HTQuGQk+KEksfOlDfpJ1FE1GsFmXARppSFmPoWU9i2ldYhS8HlAt35NpYaGPg5Kh6/lgpj+uQM2kcJ4RErPhDqxNrZTKAcQab1E/1T6eL4Z6a1z0ePq/SFrzpyTQjGn2qqUQsuuS3m4psW8nZtOwvjkQJ8mYEvl8SnTbmwGbWkrtotcnLdjUG9ZHxCp9O0gN5JW3V6Haw3rt6aOh1Ic7WvXzbYizI3CmD2n2fEwz5dXbLruqXG7bqPorqJKhjy6YH1tCmtrrWb1NrVqaE+BPu2Qq7504cVLIioluLLdGOwjn7f3PbpkkIjI5KTST+O8hXmdgfnUUWVgMB046jbRb+mpimVzKlXQ1TStgWmtb9JBvZr97le++lXTfv1suOd48aWXzTYH9pKAD+yoTifgIzz4zxTKmOgWlkMp+GBbPj1sY3IiKi9AU90Xoh4LU8t70MONjoT7xpmyvf6rN+y83lq07Q2V5+AF0LtOgsSw7CCvgfL77Yz98ibcqzZAG6bPKIL73BzYd6lrDQzbY2evdwn6kYJNt5KwryL0aXwUrnkbyg6shWNtlu1YONRV94FvzgghhBBCCCFkCODDGSGEEEIIIYQMAXw4I4QQQgghhJAh4Eg1Z845iQvhkIVyiLeeGrXPiXHdxiJnizZmdHNNdT2xvy0WrJ4lyWJNi6BXypXsEGRjrEtjY8CbKna51cbaTRADjOU+lA4gsZIAyULdIslZ/c76WtCc1SGWeBxqz8QQm5tR51QTGy+7tGxrOKxB3betatA5/Md//8j+VsniGq3Djb1O01RqWoenzvFTv/Jp+92WrdkRQTxxquLrPcQtR3D9C6B9XFwPeqOt9XNm22rdHscVrMDvxz94Z+fzyv/aGmEPnn7UtD905mHTbqm6Z0WwDQ+1lrBGWiYKNp5CWHYdtAUxxN4/cH/QnDUqK2bb+8pW+/i9l14x7asXg0atXrXXxNes1vOwiaJIyuUwT1IVU65rnomINGF+bYJeTteyikA3hNooCFeXrLLbToq6B9CQePix0rM5rP+CBdUEN4ftKehLPPyNLgV9Rqse/BzWOUuh/hgWpNJbu3Qs8NsSzJec0rplQK+mtThYl+2gcc6Z2pKlkqp5hrXq4IJHoCNLVO22TgfWD6hfubVlbauuakLhcQoFu461wOe1lW+qbdi1NQcFk8amrEZLr0XtmtXoRlBLKQcaKp8N/cJaZHmozTYBdbr8Zqi/5jL2fBtb1p/UazAe6hqh1vGoiyw6ceJcONesqleImlVJbDubhfsC1XUP55WHtUxge06ZiBM711BHlsBc1WOGWrbpGauNbMO+tCa0W9tmr1u1arX2i0uhtuqpU6fNtq0qrnvWNvVgdbAOJGrQ4Hz1OaJ/ySgfd71h758Og0T5dq8+O/AXObh38XXQN6khmBux3335tddNe+WqvT/pqNpmN0DbtQl+rATXuKS+noc++5ztB461nrtYjxSv4WZiz1drqVGXnMMlA+8RVT8zMejTxB5nvWJr5UY+7CufsTUjXbr3Ry6+OSOEEEIIIYSQIYAPZ4QQQgghhBAyBPDhjBBCCCGEEEKGgCPVnKWpk0pFxY1GozsfR0esTiZbtHGeI1Cga3w8xJBWNm2scWVzybYhHr3dCO2x3LTZVoAY7w7U4Yjj8DyLcavZvI3FxppHpVGlk4CR74DWJ1e0XyhPhBj61VUb57wF8bTlKXtONRUT/NYFqxv60WuXTHt+yurX5u9XmquMPc7MeIinXdrae/2G/ZDJOBkZDfHJ48o8xmYfMd/F2ikF+BtETtUp8kXQQZRsDHTasHqjrS2l+yjZsZp7yGo1HirZekFvvft2aDhrK9mS1ZFduWZrAk3PTO76WUSkVbf6i2Zzw7Srqu5ZE/RT7aaN8Y8LVmM3fyzoQC5es/Nq6b23TbtRscd9+40fhD5Pg55k0uoUjgKn7MApQWgLCj81mtaftEFbqvUIqO/0EG/fgjpgTRUHj3VpsF4h6qx0PH4K9WFQRYMVX3SvUKuC+hIPNWEycfh+NgINDIBSOF3LDOvJdcnkwI9ltP+EbZ12bz3BQZNxTkaU7ipWo4t/3SyAbq5SsfNN13LLQU3BIuhbu7arg9U3rM5hfu6kaWO9oImR0K/sLGhTYPjaYueDXpuKUGMzC/4SDa+tbG1mdtRsy4H+IgJNSV6t+d7bPpVKdl9F7Ica5zpokbB92HhxpuapV8JfrE+I8jjUaRoNWoz3G+AvcGfq+1gzKguTEbWlRluJcxx+G0GdK20/KIvLQj+KY3YNPX4yXFes41ZvwX0d6obU2KE+C2ss4jjreYq6Un1/sbFq1/gDxznJqGueVd3GnAYugptK6Hei6tEtjFlfM52138027BwpK5ttOFynbLsT27GsqrGto88HnVgE65qeHxnU6MI1xHVLm2kW77dgrIpwDjoFxoiDsQEpOArLm+p+DEoASiljx70ffHNGCCGEEEIIIUPAwIcz51zBOfc959wPnXNvOOf+ZPvfTzvnvuucO++c+yfnXG7Qvsi9B+2H7BfaDrkVaD9kv9B2yH6h7ZCDYC9hjU0R+YT3vuKcy4rIt51z/y4ifyAif+m9f94597ci8jsi8jf9dtRqiVy+qHa8HsIWxmbtK+lCEdLF2ygGmZoKXa9A+tX1ddteW8lBO3yOUvu6M8WUq5gaW6V+xSdbDFOKYju8dZXy30Pm+WwKaUBrq6adqDTyCYR/rFfs+cLbfllVYZ8XztuwxvUVGxLXqtof3zd+387nxx44brbpaNK3FjelBwdiP2nakNqWSl2fhrHMOmscS0s2vO6tsxdMu6BSR+fGbRjFzJwNGTw2M27aOoxtetyGj0JEmzTqNl383FwIgzx+zIb1XVtcNO1z59407VOtkEYYwza3tuz51mo2/HBzI1wbDGtMWpAaO2/Dlt54fWbnc6tpwwrm5uZN+/gH3m+3z4btM7P3mW0FOE4PDsz3iLehK82mTg9vz6vVsiHWeN46TTmmnccwpQjieAoqVC0DYUlJB1NQ9w69cRkIaZLeIZAiIjmMJ1I0GvZ8O9APHQKF54N9RNusqdTrGHaFIYAYatVphX1h6EyhEMaxK1W66o4cgP04EcnqVOIqTCsH4TGDroO+hjkMoe9gWBasiWpf42PW58HSI4WcDZ9J1aJQGrXb2mDfjbpdT3QobikHpWegrEe1Zn9bGAs+rw7lVupw3Ky34xEpG89E1lageo7U6nYerq8H34vjmsvt6Z74wHyPT720lJRC22uE0og+9iJi7ykc+A8sTYFlLrTMIgOhh9mibfvI3o9gCnQLlM8An6DHv92y1xz9J16rWkun4YdyCh3bxy4/oMoUePgtps5Hm4jj3rfGupRGjzIeB7duiUhG9SXyvUO9pSus0V7TWDmJUWevwy88fsy0N2p2+yvvhfDN5aa9Rg0IN22CPaS6lA/cNSfw24xDm1XbMv1LYESwRugM+EXQEZUydmzGYtvnMSXhmYZhLYGdZaE8VU7104NcqdHYe0j1wDdn/iY/uaPLbv/nReQTIvLP2//+nIh8Zs9HJfcMtB+yX2g75Fag/ZD9Qtsh+4W2Qw6CPWnOnHORc+4HInJdRL4uIm+LyLr3O+9/LovI8R6//V3n3IvOuRc3Ko3dvkLucvZrP9p2trZquJncAxyU7znqJABkODgI39OENz7k3uCgfA++LSJ3PwdlO8tV2s69yp4ezrz3iff+Z0XkfhF5RkR+Zq8H8N5/3nv/tPf+6fHRwuAfkLuO/dqPtp2xsb1nuSF3Dwfle4qQlZPcGxyE78nnjjSpMRkSDsr3ZPcWRknuIg7KdmZGaDv3Kj/VquO9X3fOfUNEPiIiE865ePsvAfeLyJWBv3exJNmgYWnnnt753EytViHTsSlKC+M2znNiNjzoTWbsXzanahB/vmpvzNaXVZrdqh2CpAOTwUMMeCfsu1G3bwIxbjmCmPCthkopCm8Rs97+hWQsM2baaSbohtpt2+f8iI3FLWStDmAiF/b9oFiN1RNPWu3Pox940rRPnTmz8/mZD9u3V5evBv3Sd94enFL2luwn9ZIqLVBG/V0hbttxLmft9X/p/75p2otLoa8OxuqZZz5o2h/7yNOmvbER9F2vvvxds60K2p1z79kyBe9cuLDzuQ7aDA85yAtlm3p+czOUT9has2Nd3bTaNlTgxCr2fhweco+dPm3ak9MLpj13LGjFjj31hNk2Vba2g7omo0+CVLY4rwZxy77He5MeWuvMUOcgoJno0h8oLQyONWqyUJPgVdx/G46Lx0GNhVMakghS2mdQg+Z660AG6S2wz1qThmOVBd1Uv/PH8+nSAhXsXCzlg63iOOvzQ53XbtyK/WSck2IunKc+D5/ac8LrUi7bchtGNwjXSOukbu7bjs+4+gPDKDwwetBO15tgO0rbkbat/xgbsfo1MH+TKLrasut0tm3Pt16HNPyZ8MZ6ecOWgKmsWJ3yxMSMaa9Uw3gUijCPvD3/tVXrT7eUf8U/zPy0f6i5Vd9zcx/6WofPSQcE4pC2Ow/lFLQPSyANeTZnrwXq1WJRNgxp5yGDebfeVfmeDJYAATvGkiC6xFCUtb4Gf4s+Qp9DGzRmGZgfKfoX1Y5gfU0H6HuxbY5rzq+/77ll28lkRHL6pUbot8M+wvrRgfFK1e0+aqEW4G/fn37SvtSbV/dU55fsvF2q2uOsdeyYNJRvakKXOw6uA6bpV+sJri048lgOQmf0HwE9Xh6Ok4c0/OUo2M4k6NFGQH9ZyNp969t+LElRc115+Huyl2yNs865ie3PRRH5pIi8KSLfEJFf3/7aZ0XkS3s+KrlnoP2Q/ULbIbcC7YfsF9oO2S+0HXIQ7OXN2YKIPOeci+Tmw9wXvfdfcc6dFZHnnXN/KiKviMgXDrGf5M6F9kP2C22H3Aq0H7JfaDtkv9B2yC0z8OHMe/+qiDy1y7+/IzdjaQnpCe2H7BfaDrkVaD9kv9B2yH6h7ZCDwPWLrT3wgzl3Q0QuisiMiAwWKZE7aZwe8N7PDv7a/qDt7Is7aaxoP8PFnTROtJ3h404aK9rPcHEnjRNtZ/i4k8aqp/0c6cPZzkGde9F7//Tgb97bcJy64ZjsHY5VNxyTvcFx6oZjsnc4Vt1wTPYGx6kbjsneuVvG6qdLmUYIIYQQQggh5FDgwxkhhBBCCCGEDAG36+Hs87fpuHcaHKduOCZ7h2PVDcdkb3CcuuGY7B2OVTcck73BceqGY7J37oqxui2aM0IIIYQQQgghFoY1EkIIIYQQQsgQwIczQgghhBBCCBkCjvThzDn3y865Hzvnzjvn/ugojz3sOOdOOOe+4Zw765x7wzn3e9v/PuWc+7pz7q3t/0/e7r7eLmg/u0PbGQxtpze0n8HQfnaHtjMY2k5vaD+Dof3szt1uO0emOXPORSJyTkQ+KSKXReT7IvJb3vuzR9KBIcc5tyAiC977l51zYyLykoh8RkR+W0RWvfd/vj0xJ733f3gbu3pboP30hrbTH9pOf2g//aH99Ia20x/aTn9oP/2h/fTmbredo3xz9oyInPfev+O9b4nI8yLya0d4/KHGe3/Ne//y9uctEXlTRI7LzTF6bvtrz8lN47sXof30gLYzENpOH2g/A6H99IC2MxDaTh9oPwOh/fTgbredo3w4Oy4il1T78va/EcA5d0pEnhKR74rIvPf+2vamRRGZv03dut3QfvYAbWdXaDt7hPazK7SfPUDb2RXazh6h/ewK7WcP3I22w4QgQ4ZzblRE/kVEft97v6m3+ZsxqKx9QHaFtkNuBdoP2S+0HXIr0H7IfrlbbecoH86uiMgJ1b5/+9/INs65rNw0sn/03v/r9j8vbcfW/iTG9vrt6t9thvbTB9pOX2g7A6D99IX20wfaTl9oOwOg/fSF9tOHu9l2jvLh7Psi8rBz7rRzLicivykiXz7C4w81zjknIl8QkTe993+hNn1ZRD67/fmzIvKlo+7bkED76QFtZyC0nT7QfgZC++kBbWcgtJ0+0H4GQvvpwd1uO0eWrVFExDn3qyLyORGJROTvvPd/dmQHH3Kccx8Tkf8RkddEJN3+5z+WmzG0XxSRkyJyUUR+w3u/els6eZuh/ewObWcwtJ3e0H4GQ/vZHdrOYGg7vaH9DIb2szt3u+0c6cMZIYQQQgghhJDdYUIQQgghhBBCCBkC+HBGCCGEEEIIIUMAH84IIYQQQgghZAjgwxkhhBBCCCGEDAF8OCOEEEIIIYSQIYAPZ4QQQgghhBAyBPDhjBBCCCGEEEKGgP8H09FbQn15zhEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMG4ttoHVj02"
      },
      "source": [
        "And, as usual,\n",
        "- we normalize the data between 0 and 1\n",
        "- we create `y` as one-hot-encoded version of `labels`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T17:30:36.240227Z",
          "start_time": "2021-04-28T17:30:34.949442Z"
        },
        "id": "Fm8XRTbiVj02"
      },
      "source": [
        "X_train = images_train / 255.\n",
        "X_train_small = images_train_small / 255.\n",
        "X_test = images_test / 255.\n",
        "X_test_small = images_test_small / 255.\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train = to_categorical(labels_train, 10)\n",
        "y_train_small = to_categorical(labels_train_small, 10)\n",
        "y_test = to_categorical(labels_test, 10)\n",
        "y_test_small = to_categorical(labels_test_small, 10)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLYcUuZwm0sN",
        "outputId": "4d385196-31a3-44dd-da90-e092d84c4d92"
      },
      "source": [
        "y_train_small.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4tyYVJm45w",
        "outputId": "3fe3917d-0185-43c8-b4ec-ca3448ddc8c4"
      },
      "source": [
        "y_test_small.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke9YJk7MVj04"
      },
      "source": [
        "## 2. Iterate on your CNN architecture using your small training set\n",
        "\n",
        "\n",
        "❓ **Question** ❓ Your turn to shine!\n",
        "\n",
        "- Define the CNN architecture of your choice in a method `initialize_model()`\n",
        "- Compile your model in a method `compile_model()`:\n",
        "- Fit it on your **small** training set **only**\n",
        "- Store the output of the fit in an `history` variable\n",
        "- Try a first model yourself, before looking at PRO TIPS below\n",
        " \n",
        "<details>\n",
        "    <summary> 🆘 PRO TIPS 🆘  </summary>\n",
        "\n",
        "\n",
        "- Do not forget to add the input shape of your data to the first layer: it has 3 colors\n",
        "- Start simple, complexify after few trials to get better results\n",
        "- The task is complex: Try at least 3 or 4 convolutions\n",
        "- Kernel size do not need to be large for such small picture resolution!\n",
        "- Add some Maxpooling (but not too much else the activation \"image\" will become too small)\n",
        "- Keep padding = 'same' and 'stride' = (1,1) to start with.\n",
        "- Once your model overfits, try adding some dropout layer to regularize the network. A good tip is too increase dropout strengh as you move closer to the output, so as not to overfit on your end-result\n",
        "- Images are so small, that you can use larger batch size (32 or 64) to benefit from even more GPU parallelization\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSSft1k9pzck"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNOtE5xhVj04"
      },
      "source": [
        "def initialize_model():\n",
        "    '''instanciate and return the CNN architecture of your choice with less than 150,000 params'''\n",
        "    \n",
        "    model = models.Sequential()\n",
        "    \n",
        "    model.add(layers.Conv2D(32,(3,3), strides=(1,1),input_shape=(32, 32, 3), padding = 'same', activation=\"relu\"))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second convolution & max-pooling\n",
        "    model.add(layers.Conv2D(64, (3,3), padding = 'same', activation=\"relu\"))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3,3), padding = 'same', activation=\"relu\"))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    \n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    ### One fully connected\n",
        "    model.add(layers.Dense(100, activation='relu'))\n",
        "    \n",
        "    model.add(layers.Dropout(0.4))\n",
        "\n",
        "    ### Last layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm7Dttfm1ef8"
      },
      "source": [
        "def initialize_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "    #model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    #model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
        "    #model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(100, activation='relu'))\n",
        "    model.add(layers.Dropout(0.4))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C9AL4uBT2Iq"
      },
      "source": [
        "def compile_model(model):\n",
        "    '''return a compiled model suited for the cifar tasks'''\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG5RRA0LplcN"
      },
      "source": [
        "model = initialize_model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV4yOdZjyK19",
        "outputId": "462493de-9160-4672-9984-fcd5ad6f366a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 128)         32896     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               204900    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 258,198\n",
            "Trainable params: 258,198\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126kh7wzp21L",
        "outputId": "4b5e6146-2cd5-4fa2-8da3-f1d0bbe92abf"
      },
      "source": [
        "compile_model(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f650d1255d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lV1WosKkn45U",
        "outputId": "49801249-8605-4778-e652-b0c1c734aa4b"
      },
      "source": [
        "history = model.fit(X_train_small, y_train_small, validation_data = (X_test_small, y_test_small), epochs = 500, batch_size = 32, verbose = 1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "157/157 [==============================] - 1s 6ms/step - loss: 0.3616 - accuracy: 0.8770 - val_loss: 1.3870 - val_accuracy: 0.6120\n",
            "Epoch 2/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3580 - accuracy: 0.8702 - val_loss: 1.4459 - val_accuracy: 0.6170\n",
            "Epoch 3/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3693 - accuracy: 0.8632 - val_loss: 1.4697 - val_accuracy: 0.6010\n",
            "Epoch 4/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3625 - accuracy: 0.8680 - val_loss: 1.5020 - val_accuracy: 0.6090\n",
            "Epoch 5/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3722 - accuracy: 0.8696 - val_loss: 1.5038 - val_accuracy: 0.6170\n",
            "Epoch 6/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3213 - accuracy: 0.8846 - val_loss: 1.4459 - val_accuracy: 0.6180\n",
            "Epoch 7/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.8772 - val_loss: 1.5286 - val_accuracy: 0.6030\n",
            "Epoch 8/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3486 - accuracy: 0.8754 - val_loss: 1.4424 - val_accuracy: 0.6080\n",
            "Epoch 9/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3293 - accuracy: 0.8766 - val_loss: 1.4355 - val_accuracy: 0.6150\n",
            "Epoch 10/500\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3480 - accuracy: 0.8788 - val_loss: 1.4770 - val_accuracy: 0.6160\n",
            "Epoch 11/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3466 - accuracy: 0.8734 - val_loss: 1.4289 - val_accuracy: 0.6110\n",
            "Epoch 12/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3431 - accuracy: 0.8732 - val_loss: 1.4514 - val_accuracy: 0.6190\n",
            "Epoch 13/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3018 - accuracy: 0.8888 - val_loss: 1.5721 - val_accuracy: 0.6180\n",
            "Epoch 14/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3107 - accuracy: 0.8928 - val_loss: 1.4959 - val_accuracy: 0.6110\n",
            "Epoch 15/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8800 - val_loss: 1.4909 - val_accuracy: 0.6060\n",
            "Epoch 16/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3394 - accuracy: 0.8798 - val_loss: 1.5326 - val_accuracy: 0.6070\n",
            "Epoch 17/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3507 - accuracy: 0.8750 - val_loss: 1.4289 - val_accuracy: 0.6240\n",
            "Epoch 18/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3277 - accuracy: 0.8810 - val_loss: 1.4452 - val_accuracy: 0.6120\n",
            "Epoch 19/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3211 - accuracy: 0.8784 - val_loss: 1.4680 - val_accuracy: 0.6200\n",
            "Epoch 20/500\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 0.3110 - accuracy: 0.8860 - val_loss: 1.4721 - val_accuracy: 0.6180\n",
            "Epoch 21/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3186 - accuracy: 0.8840 - val_loss: 1.4568 - val_accuracy: 0.6220\n",
            "Epoch 22/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3270 - accuracy: 0.8782 - val_loss: 1.6862 - val_accuracy: 0.6110\n",
            "Epoch 23/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3288 - accuracy: 0.8858 - val_loss: 1.5188 - val_accuracy: 0.6080\n",
            "Epoch 24/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3043 - accuracy: 0.8882 - val_loss: 1.5368 - val_accuracy: 0.6160\n",
            "Epoch 25/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3188 - accuracy: 0.8866 - val_loss: 1.5426 - val_accuracy: 0.6230\n",
            "Epoch 26/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3204 - accuracy: 0.8826 - val_loss: 1.5006 - val_accuracy: 0.6280\n",
            "Epoch 27/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.8922 - val_loss: 1.5269 - val_accuracy: 0.6150\n",
            "Epoch 28/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3376 - accuracy: 0.8824 - val_loss: 1.4860 - val_accuracy: 0.6130\n",
            "Epoch 29/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3055 - accuracy: 0.8912 - val_loss: 1.4715 - val_accuracy: 0.6200\n",
            "Epoch 30/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3182 - accuracy: 0.8854 - val_loss: 1.5449 - val_accuracy: 0.6240\n",
            "Epoch 31/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2829 - accuracy: 0.8952 - val_loss: 1.4960 - val_accuracy: 0.6370\n",
            "Epoch 32/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.8994 - val_loss: 1.5442 - val_accuracy: 0.6270\n",
            "Epoch 33/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.8966 - val_loss: 1.5470 - val_accuracy: 0.6150\n",
            "Epoch 34/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3088 - accuracy: 0.8908 - val_loss: 1.5052 - val_accuracy: 0.6110\n",
            "Epoch 35/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3189 - accuracy: 0.8902 - val_loss: 1.5001 - val_accuracy: 0.6260\n",
            "Epoch 36/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2951 - accuracy: 0.8954 - val_loss: 1.5783 - val_accuracy: 0.6090\n",
            "Epoch 37/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2892 - accuracy: 0.8940 - val_loss: 1.4654 - val_accuracy: 0.6230\n",
            "Epoch 38/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3011 - accuracy: 0.8944 - val_loss: 1.5511 - val_accuracy: 0.6180\n",
            "Epoch 39/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3068 - accuracy: 0.8906 - val_loss: 1.4875 - val_accuracy: 0.6320\n",
            "Epoch 40/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2995 - accuracy: 0.8930 - val_loss: 1.4987 - val_accuracy: 0.6100\n",
            "Epoch 41/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3056 - accuracy: 0.8918 - val_loss: 1.6018 - val_accuracy: 0.6000\n",
            "Epoch 42/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2983 - accuracy: 0.8940 - val_loss: 1.4874 - val_accuracy: 0.6250\n",
            "Epoch 43/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2853 - accuracy: 0.8990 - val_loss: 1.4596 - val_accuracy: 0.6270\n",
            "Epoch 44/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2891 - accuracy: 0.8992 - val_loss: 1.5213 - val_accuracy: 0.6140\n",
            "Epoch 45/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3142 - accuracy: 0.8856 - val_loss: 1.5745 - val_accuracy: 0.6110\n",
            "Epoch 46/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.3000 - accuracy: 0.8940 - val_loss: 1.4616 - val_accuracy: 0.6200\n",
            "Epoch 47/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2888 - accuracy: 0.8990 - val_loss: 1.4680 - val_accuracy: 0.6260\n",
            "Epoch 48/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2815 - accuracy: 0.9004 - val_loss: 1.5860 - val_accuracy: 0.6170\n",
            "Epoch 49/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2600 - accuracy: 0.9050 - val_loss: 1.5622 - val_accuracy: 0.6210\n",
            "Epoch 50/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2797 - accuracy: 0.9008 - val_loss: 1.5264 - val_accuracy: 0.6210\n",
            "Epoch 51/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2756 - accuracy: 0.8968 - val_loss: 1.4690 - val_accuracy: 0.6230\n",
            "Epoch 52/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2614 - accuracy: 0.9040 - val_loss: 1.5308 - val_accuracy: 0.6180\n",
            "Epoch 53/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.9056 - val_loss: 1.4839 - val_accuracy: 0.6150\n",
            "Epoch 54/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2672 - accuracy: 0.9010 - val_loss: 1.4982 - val_accuracy: 0.6300\n",
            "Epoch 55/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2717 - accuracy: 0.9046 - val_loss: 1.5563 - val_accuracy: 0.6360\n",
            "Epoch 56/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2764 - accuracy: 0.9008 - val_loss: 1.5425 - val_accuracy: 0.6290\n",
            "Epoch 57/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2776 - accuracy: 0.9028 - val_loss: 1.5382 - val_accuracy: 0.6270\n",
            "Epoch 58/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2814 - accuracy: 0.8960 - val_loss: 1.5621 - val_accuracy: 0.6300\n",
            "Epoch 59/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2774 - accuracy: 0.8986 - val_loss: 1.5749 - val_accuracy: 0.6290\n",
            "Epoch 60/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2666 - accuracy: 0.9048 - val_loss: 1.6408 - val_accuracy: 0.6270\n",
            "Epoch 61/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2690 - accuracy: 0.9078 - val_loss: 1.5962 - val_accuracy: 0.6220\n",
            "Epoch 62/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2592 - accuracy: 0.9084 - val_loss: 1.6113 - val_accuracy: 0.6200\n",
            "Epoch 63/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2786 - accuracy: 0.9036 - val_loss: 1.6049 - val_accuracy: 0.6100\n",
            "Epoch 64/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2957 - accuracy: 0.8954 - val_loss: 1.5793 - val_accuracy: 0.5930\n",
            "Epoch 65/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2570 - accuracy: 0.9034 - val_loss: 1.5905 - val_accuracy: 0.6240\n",
            "Epoch 66/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2601 - accuracy: 0.9040 - val_loss: 1.6720 - val_accuracy: 0.6340\n",
            "Epoch 67/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2641 - accuracy: 0.9074 - val_loss: 1.6328 - val_accuracy: 0.6380\n",
            "Epoch 68/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2822 - accuracy: 0.8994 - val_loss: 1.5100 - val_accuracy: 0.6140\n",
            "Epoch 69/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2676 - accuracy: 0.9032 - val_loss: 1.6459 - val_accuracy: 0.6230\n",
            "Epoch 70/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2747 - accuracy: 0.9022 - val_loss: 1.6057 - val_accuracy: 0.6220\n",
            "Epoch 71/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2834 - accuracy: 0.8954 - val_loss: 1.4751 - val_accuracy: 0.6240\n",
            "Epoch 72/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2585 - accuracy: 0.9046 - val_loss: 1.5846 - val_accuracy: 0.6290\n",
            "Epoch 73/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2703 - accuracy: 0.9038 - val_loss: 1.5462 - val_accuracy: 0.6170\n",
            "Epoch 74/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.9134 - val_loss: 1.6403 - val_accuracy: 0.6260\n",
            "Epoch 75/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2545 - accuracy: 0.9124 - val_loss: 1.6714 - val_accuracy: 0.6130\n",
            "Epoch 76/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2582 - accuracy: 0.9106 - val_loss: 1.5707 - val_accuracy: 0.6320\n",
            "Epoch 77/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2430 - accuracy: 0.9164 - val_loss: 1.7024 - val_accuracy: 0.6200\n",
            "Epoch 78/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2659 - accuracy: 0.9088 - val_loss: 1.5650 - val_accuracy: 0.6120\n",
            "Epoch 79/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2363 - accuracy: 0.9158 - val_loss: 1.6443 - val_accuracy: 0.6050\n",
            "Epoch 80/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2388 - accuracy: 0.9132 - val_loss: 1.6316 - val_accuracy: 0.6300\n",
            "Epoch 81/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2623 - accuracy: 0.9104 - val_loss: 1.5755 - val_accuracy: 0.6080\n",
            "Epoch 82/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2453 - accuracy: 0.9128 - val_loss: 1.6881 - val_accuracy: 0.6130\n",
            "Epoch 83/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2473 - accuracy: 0.9110 - val_loss: 1.6161 - val_accuracy: 0.6220\n",
            "Epoch 84/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2612 - accuracy: 0.9146 - val_loss: 1.5787 - val_accuracy: 0.6130\n",
            "Epoch 85/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2585 - accuracy: 0.9114 - val_loss: 1.6627 - val_accuracy: 0.6100\n",
            "Epoch 86/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2646 - accuracy: 0.9084 - val_loss: 1.6769 - val_accuracy: 0.6180\n",
            "Epoch 87/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9192 - val_loss: 1.6338 - val_accuracy: 0.6430\n",
            "Epoch 88/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2443 - accuracy: 0.9140 - val_loss: 1.6106 - val_accuracy: 0.6240\n",
            "Epoch 89/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2469 - accuracy: 0.9090 - val_loss: 1.5951 - val_accuracy: 0.6150\n",
            "Epoch 90/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2293 - accuracy: 0.9190 - val_loss: 1.6723 - val_accuracy: 0.6220\n",
            "Epoch 91/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2587 - accuracy: 0.9036 - val_loss: 1.6289 - val_accuracy: 0.6260\n",
            "Epoch 92/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2513 - accuracy: 0.9118 - val_loss: 1.5810 - val_accuracy: 0.6250\n",
            "Epoch 93/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2552 - accuracy: 0.9172 - val_loss: 1.6154 - val_accuracy: 0.6310\n",
            "Epoch 94/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2426 - accuracy: 0.9130 - val_loss: 1.6395 - val_accuracy: 0.6180\n",
            "Epoch 95/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2382 - accuracy: 0.9166 - val_loss: 1.6077 - val_accuracy: 0.6410\n",
            "Epoch 96/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2379 - accuracy: 0.9158 - val_loss: 1.7114 - val_accuracy: 0.6280\n",
            "Epoch 97/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2451 - accuracy: 0.9140 - val_loss: 1.6990 - val_accuracy: 0.6170\n",
            "Epoch 98/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2524 - accuracy: 0.9126 - val_loss: 1.5383 - val_accuracy: 0.6200\n",
            "Epoch 99/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2422 - accuracy: 0.9090 - val_loss: 1.6933 - val_accuracy: 0.6160\n",
            "Epoch 100/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2260 - accuracy: 0.9234 - val_loss: 1.7222 - val_accuracy: 0.6270\n",
            "Epoch 101/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2079 - accuracy: 0.9304 - val_loss: 1.6235 - val_accuracy: 0.6200\n",
            "Epoch 102/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2203 - accuracy: 0.9202 - val_loss: 1.7269 - val_accuracy: 0.6230\n",
            "Epoch 103/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2265 - accuracy: 0.9206 - val_loss: 1.7509 - val_accuracy: 0.6140\n",
            "Epoch 104/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2488 - accuracy: 0.9118 - val_loss: 1.5980 - val_accuracy: 0.6270\n",
            "Epoch 105/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.9144 - val_loss: 1.6592 - val_accuracy: 0.6180\n",
            "Epoch 106/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2442 - accuracy: 0.9160 - val_loss: 1.6459 - val_accuracy: 0.6130\n",
            "Epoch 107/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2372 - accuracy: 0.9174 - val_loss: 1.6540 - val_accuracy: 0.6340\n",
            "Epoch 108/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2374 - accuracy: 0.9190 - val_loss: 1.5613 - val_accuracy: 0.6480\n",
            "Epoch 109/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2224 - accuracy: 0.9228 - val_loss: 1.6933 - val_accuracy: 0.6300\n",
            "Epoch 110/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2401 - accuracy: 0.9152 - val_loss: 1.6423 - val_accuracy: 0.6390\n",
            "Epoch 111/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2457 - accuracy: 0.9134 - val_loss: 1.6959 - val_accuracy: 0.6200\n",
            "Epoch 112/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.9188 - val_loss: 1.6054 - val_accuracy: 0.6300\n",
            "Epoch 113/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9234 - val_loss: 1.6158 - val_accuracy: 0.6330\n",
            "Epoch 114/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2286 - accuracy: 0.9144 - val_loss: 1.6559 - val_accuracy: 0.6370\n",
            "Epoch 115/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2010 - accuracy: 0.9242 - val_loss: 1.6624 - val_accuracy: 0.6370\n",
            "Epoch 116/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2165 - accuracy: 0.9208 - val_loss: 1.5880 - val_accuracy: 0.6310\n",
            "Epoch 117/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.9142 - val_loss: 1.5479 - val_accuracy: 0.6250\n",
            "Epoch 118/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2266 - accuracy: 0.9212 - val_loss: 1.6338 - val_accuracy: 0.6180\n",
            "Epoch 119/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2231 - accuracy: 0.9246 - val_loss: 1.5306 - val_accuracy: 0.6230\n",
            "Epoch 120/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2313 - accuracy: 0.9224 - val_loss: 1.6249 - val_accuracy: 0.6160\n",
            "Epoch 121/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2288 - accuracy: 0.9208 - val_loss: 1.6806 - val_accuracy: 0.6340\n",
            "Epoch 122/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2191 - accuracy: 0.9206 - val_loss: 1.6191 - val_accuracy: 0.6210\n",
            "Epoch 123/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2215 - accuracy: 0.9218 - val_loss: 1.7003 - val_accuracy: 0.6300\n",
            "Epoch 124/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9272 - val_loss: 1.7674 - val_accuracy: 0.6180\n",
            "Epoch 125/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2084 - accuracy: 0.9242 - val_loss: 1.6292 - val_accuracy: 0.6400\n",
            "Epoch 126/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2081 - accuracy: 0.9222 - val_loss: 1.6583 - val_accuracy: 0.6250\n",
            "Epoch 127/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2188 - accuracy: 0.9260 - val_loss: 1.6652 - val_accuracy: 0.6360\n",
            "Epoch 128/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9292 - val_loss: 1.6369 - val_accuracy: 0.6240\n",
            "Epoch 129/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2265 - accuracy: 0.9224 - val_loss: 1.6806 - val_accuracy: 0.6080\n",
            "Epoch 130/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2151 - accuracy: 0.9212 - val_loss: 1.7866 - val_accuracy: 0.6260\n",
            "Epoch 131/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2188 - accuracy: 0.9272 - val_loss: 1.6440 - val_accuracy: 0.6330\n",
            "Epoch 132/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2216 - accuracy: 0.9228 - val_loss: 1.7940 - val_accuracy: 0.6190\n",
            "Epoch 133/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2149 - accuracy: 0.9252 - val_loss: 1.6946 - val_accuracy: 0.6360\n",
            "Epoch 134/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2237 - accuracy: 0.9238 - val_loss: 1.7139 - val_accuracy: 0.6320\n",
            "Epoch 135/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.9266 - val_loss: 1.6625 - val_accuracy: 0.6310\n",
            "Epoch 136/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9280 - val_loss: 1.6759 - val_accuracy: 0.6310\n",
            "Epoch 137/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.9230 - val_loss: 1.7290 - val_accuracy: 0.6120\n",
            "Epoch 138/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2313 - accuracy: 0.9184 - val_loss: 1.6424 - val_accuracy: 0.6110\n",
            "Epoch 139/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2222 - accuracy: 0.9244 - val_loss: 1.6327 - val_accuracy: 0.6290\n",
            "Epoch 140/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2134 - accuracy: 0.9244 - val_loss: 1.6627 - val_accuracy: 0.6290\n",
            "Epoch 141/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2140 - accuracy: 0.9278 - val_loss: 1.5943 - val_accuracy: 0.6340\n",
            "Epoch 142/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2175 - accuracy: 0.9204 - val_loss: 1.7470 - val_accuracy: 0.6250\n",
            "Epoch 143/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2164 - accuracy: 0.9280 - val_loss: 1.6500 - val_accuracy: 0.6390\n",
            "Epoch 144/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2104 - accuracy: 0.9312 - val_loss: 1.7780 - val_accuracy: 0.6190\n",
            "Epoch 145/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2276 - accuracy: 0.9234 - val_loss: 1.7492 - val_accuracy: 0.6220\n",
            "Epoch 146/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1958 - accuracy: 0.9338 - val_loss: 1.7982 - val_accuracy: 0.6190\n",
            "Epoch 147/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2138 - accuracy: 0.9240 - val_loss: 1.7690 - val_accuracy: 0.6210\n",
            "Epoch 148/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9260 - val_loss: 1.8184 - val_accuracy: 0.6300\n",
            "Epoch 149/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2333 - accuracy: 0.9210 - val_loss: 1.7244 - val_accuracy: 0.6100\n",
            "Epoch 150/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9238 - val_loss: 1.7479 - val_accuracy: 0.6230\n",
            "Epoch 151/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2032 - accuracy: 0.9298 - val_loss: 1.6710 - val_accuracy: 0.6320\n",
            "Epoch 152/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1980 - accuracy: 0.9298 - val_loss: 1.7908 - val_accuracy: 0.6240\n",
            "Epoch 153/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1834 - accuracy: 0.9338 - val_loss: 1.7594 - val_accuracy: 0.6240\n",
            "Epoch 154/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9240 - val_loss: 1.8010 - val_accuracy: 0.6130\n",
            "Epoch 155/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2080 - accuracy: 0.9286 - val_loss: 1.6974 - val_accuracy: 0.6130\n",
            "Epoch 156/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2038 - accuracy: 0.9310 - val_loss: 1.6797 - val_accuracy: 0.6260\n",
            "Epoch 157/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9206 - val_loss: 1.6798 - val_accuracy: 0.6280\n",
            "Epoch 158/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1884 - accuracy: 0.9314 - val_loss: 1.8795 - val_accuracy: 0.6280\n",
            "Epoch 159/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2189 - accuracy: 0.9238 - val_loss: 1.7233 - val_accuracy: 0.6130\n",
            "Epoch 160/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2071 - accuracy: 0.9294 - val_loss: 1.6936 - val_accuracy: 0.6240\n",
            "Epoch 161/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.9230 - val_loss: 1.7238 - val_accuracy: 0.6370\n",
            "Epoch 162/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2046 - accuracy: 0.9260 - val_loss: 1.7428 - val_accuracy: 0.6110\n",
            "Epoch 163/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1993 - accuracy: 0.9306 - val_loss: 1.7048 - val_accuracy: 0.6140\n",
            "Epoch 164/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2271 - accuracy: 0.9238 - val_loss: 1.6608 - val_accuracy: 0.6140\n",
            "Epoch 165/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2088 - accuracy: 0.9302 - val_loss: 1.6894 - val_accuracy: 0.6310\n",
            "Epoch 166/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1965 - accuracy: 0.9306 - val_loss: 1.6774 - val_accuracy: 0.6270\n",
            "Epoch 167/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2033 - accuracy: 0.9296 - val_loss: 1.7556 - val_accuracy: 0.6230\n",
            "Epoch 168/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1937 - accuracy: 0.9334 - val_loss: 1.7971 - val_accuracy: 0.6330\n",
            "Epoch 169/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1993 - accuracy: 0.9284 - val_loss: 1.7971 - val_accuracy: 0.6230\n",
            "Epoch 170/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2061 - accuracy: 0.9252 - val_loss: 1.8778 - val_accuracy: 0.6120\n",
            "Epoch 171/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1962 - accuracy: 0.9318 - val_loss: 1.7829 - val_accuracy: 0.6220\n",
            "Epoch 172/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2097 - accuracy: 0.9258 - val_loss: 1.7652 - val_accuracy: 0.6130\n",
            "Epoch 173/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2059 - accuracy: 0.9282 - val_loss: 1.7352 - val_accuracy: 0.6190\n",
            "Epoch 174/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2194 - accuracy: 0.9248 - val_loss: 1.7508 - val_accuracy: 0.6400\n",
            "Epoch 175/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.9310 - val_loss: 1.7511 - val_accuracy: 0.6100\n",
            "Epoch 176/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1909 - accuracy: 0.9306 - val_loss: 1.7533 - val_accuracy: 0.6220\n",
            "Epoch 177/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2037 - accuracy: 0.9284 - val_loss: 1.6887 - val_accuracy: 0.6270\n",
            "Epoch 178/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1944 - accuracy: 0.9270 - val_loss: 1.8037 - val_accuracy: 0.6290\n",
            "Epoch 179/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2004 - accuracy: 0.9306 - val_loss: 1.7975 - val_accuracy: 0.6180\n",
            "Epoch 180/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9366 - val_loss: 1.9768 - val_accuracy: 0.6180\n",
            "Epoch 181/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1943 - accuracy: 0.9290 - val_loss: 1.7745 - val_accuracy: 0.6160\n",
            "Epoch 182/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2158 - accuracy: 0.9284 - val_loss: 1.7525 - val_accuracy: 0.6380\n",
            "Epoch 183/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1883 - accuracy: 0.9382 - val_loss: 1.8427 - val_accuracy: 0.6320\n",
            "Epoch 184/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9244 - val_loss: 1.7713 - val_accuracy: 0.6230\n",
            "Epoch 185/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9402 - val_loss: 1.7505 - val_accuracy: 0.6140\n",
            "Epoch 186/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1980 - accuracy: 0.9316 - val_loss: 1.8055 - val_accuracy: 0.6310\n",
            "Epoch 187/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.9312 - val_loss: 1.7136 - val_accuracy: 0.6170\n",
            "Epoch 188/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1709 - accuracy: 0.9386 - val_loss: 1.8389 - val_accuracy: 0.6230\n",
            "Epoch 189/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1735 - accuracy: 0.9378 - val_loss: 1.8249 - val_accuracy: 0.6040\n",
            "Epoch 190/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1882 - accuracy: 0.9364 - val_loss: 1.7645 - val_accuracy: 0.6140\n",
            "Epoch 191/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1996 - accuracy: 0.9294 - val_loss: 1.7015 - val_accuracy: 0.6340\n",
            "Epoch 192/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.9316 - val_loss: 1.7513 - val_accuracy: 0.6280\n",
            "Epoch 193/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1941 - accuracy: 0.9346 - val_loss: 1.7976 - val_accuracy: 0.6180\n",
            "Epoch 194/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2125 - accuracy: 0.9328 - val_loss: 1.8091 - val_accuracy: 0.6110\n",
            "Epoch 195/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1921 - accuracy: 0.9338 - val_loss: 1.7456 - val_accuracy: 0.6280\n",
            "Epoch 196/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1778 - accuracy: 0.9374 - val_loss: 1.7849 - val_accuracy: 0.6140\n",
            "Epoch 197/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1783 - accuracy: 0.9382 - val_loss: 1.8275 - val_accuracy: 0.6220\n",
            "Epoch 198/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2187 - accuracy: 0.9276 - val_loss: 1.6998 - val_accuracy: 0.6150\n",
            "Epoch 199/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9294 - val_loss: 1.7516 - val_accuracy: 0.6240\n",
            "Epoch 200/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1853 - accuracy: 0.9348 - val_loss: 1.7367 - val_accuracy: 0.6280\n",
            "Epoch 201/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1877 - accuracy: 0.9338 - val_loss: 1.7977 - val_accuracy: 0.6240\n",
            "Epoch 202/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1972 - accuracy: 0.9316 - val_loss: 1.6992 - val_accuracy: 0.6260\n",
            "Epoch 203/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2126 - accuracy: 0.9288 - val_loss: 1.7584 - val_accuracy: 0.6310\n",
            "Epoch 204/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1943 - accuracy: 0.9344 - val_loss: 1.7488 - val_accuracy: 0.6290\n",
            "Epoch 205/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1868 - accuracy: 0.9338 - val_loss: 1.7612 - val_accuracy: 0.6160\n",
            "Epoch 206/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9384 - val_loss: 1.7030 - val_accuracy: 0.6260\n",
            "Epoch 207/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1797 - accuracy: 0.9372 - val_loss: 1.7642 - val_accuracy: 0.6140\n",
            "Epoch 208/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1993 - accuracy: 0.9328 - val_loss: 1.7014 - val_accuracy: 0.6160\n",
            "Epoch 209/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1800 - accuracy: 0.9390 - val_loss: 1.7273 - val_accuracy: 0.6190\n",
            "Epoch 210/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9340 - val_loss: 1.7247 - val_accuracy: 0.6310\n",
            "Epoch 211/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1848 - accuracy: 0.9368 - val_loss: 1.7665 - val_accuracy: 0.6140\n",
            "Epoch 212/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2050 - accuracy: 0.9278 - val_loss: 1.7800 - val_accuracy: 0.6220\n",
            "Epoch 213/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1927 - accuracy: 0.9324 - val_loss: 1.7497 - val_accuracy: 0.6120\n",
            "Epoch 214/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1787 - accuracy: 0.9326 - val_loss: 1.7635 - val_accuracy: 0.6280\n",
            "Epoch 215/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1929 - accuracy: 0.9306 - val_loss: 1.7598 - val_accuracy: 0.6260\n",
            "Epoch 216/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1828 - accuracy: 0.9398 - val_loss: 1.7404 - val_accuracy: 0.6240\n",
            "Epoch 217/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1878 - accuracy: 0.9392 - val_loss: 1.8103 - val_accuracy: 0.6200\n",
            "Epoch 218/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1720 - accuracy: 0.9446 - val_loss: 1.7790 - val_accuracy: 0.6360\n",
            "Epoch 219/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1788 - accuracy: 0.9366 - val_loss: 1.7594 - val_accuracy: 0.6240\n",
            "Epoch 220/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1661 - accuracy: 0.9474 - val_loss: 1.7630 - val_accuracy: 0.6320\n",
            "Epoch 221/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1864 - accuracy: 0.9312 - val_loss: 1.7381 - val_accuracy: 0.6220\n",
            "Epoch 222/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1950 - accuracy: 0.9372 - val_loss: 1.7541 - val_accuracy: 0.6300\n",
            "Epoch 223/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1594 - accuracy: 0.9434 - val_loss: 1.9317 - val_accuracy: 0.6140\n",
            "Epoch 224/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1681 - accuracy: 0.9420 - val_loss: 1.8932 - val_accuracy: 0.6200\n",
            "Epoch 225/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1730 - accuracy: 0.9394 - val_loss: 1.9479 - val_accuracy: 0.6260\n",
            "Epoch 226/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9390 - val_loss: 1.8691 - val_accuracy: 0.6200\n",
            "Epoch 227/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1913 - accuracy: 0.9372 - val_loss: 1.7232 - val_accuracy: 0.6350\n",
            "Epoch 228/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1926 - accuracy: 0.9354 - val_loss: 1.8478 - val_accuracy: 0.6180\n",
            "Epoch 229/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.9314 - val_loss: 1.8316 - val_accuracy: 0.6280\n",
            "Epoch 230/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1728 - accuracy: 0.9404 - val_loss: 1.8379 - val_accuracy: 0.6230\n",
            "Epoch 231/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1909 - accuracy: 0.9336 - val_loss: 1.6971 - val_accuracy: 0.6250\n",
            "Epoch 232/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1998 - accuracy: 0.9342 - val_loss: 1.7112 - val_accuracy: 0.6210\n",
            "Epoch 233/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1982 - accuracy: 0.9352 - val_loss: 1.8481 - val_accuracy: 0.6020\n",
            "Epoch 234/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1859 - accuracy: 0.9316 - val_loss: 1.7782 - val_accuracy: 0.6090\n",
            "Epoch 235/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1894 - accuracy: 0.9374 - val_loss: 1.8328 - val_accuracy: 0.6120\n",
            "Epoch 236/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1854 - accuracy: 0.9376 - val_loss: 1.7984 - val_accuracy: 0.6350\n",
            "Epoch 237/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1833 - accuracy: 0.9360 - val_loss: 1.7466 - val_accuracy: 0.6270\n",
            "Epoch 238/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1941 - accuracy: 0.9358 - val_loss: 1.7627 - val_accuracy: 0.6390\n",
            "Epoch 239/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1861 - accuracy: 0.9392 - val_loss: 1.6709 - val_accuracy: 0.6580\n",
            "Epoch 240/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9394 - val_loss: 1.7585 - val_accuracy: 0.6320\n",
            "Epoch 241/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1735 - accuracy: 0.9400 - val_loss: 1.7082 - val_accuracy: 0.6290\n",
            "Epoch 242/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1758 - accuracy: 0.9398 - val_loss: 1.7892 - val_accuracy: 0.6370\n",
            "Epoch 243/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1832 - accuracy: 0.9376 - val_loss: 1.7224 - val_accuracy: 0.6470\n",
            "Epoch 244/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1732 - accuracy: 0.9418 - val_loss: 1.7240 - val_accuracy: 0.6410\n",
            "Epoch 245/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1760 - accuracy: 0.9404 - val_loss: 1.8232 - val_accuracy: 0.6130\n",
            "Epoch 246/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1609 - accuracy: 0.9448 - val_loss: 1.7628 - val_accuracy: 0.6260\n",
            "Epoch 247/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1590 - accuracy: 0.9444 - val_loss: 1.8367 - val_accuracy: 0.6150\n",
            "Epoch 248/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1715 - accuracy: 0.9422 - val_loss: 1.8362 - val_accuracy: 0.6320\n",
            "Epoch 249/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1688 - accuracy: 0.9402 - val_loss: 1.8443 - val_accuracy: 0.6320\n",
            "Epoch 250/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2072 - accuracy: 0.9306 - val_loss: 1.7262 - val_accuracy: 0.6410\n",
            "Epoch 251/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.9382 - val_loss: 1.8602 - val_accuracy: 0.6260\n",
            "Epoch 252/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1658 - accuracy: 0.9420 - val_loss: 1.9228 - val_accuracy: 0.6280\n",
            "Epoch 253/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1748 - accuracy: 0.9396 - val_loss: 1.8537 - val_accuracy: 0.6220\n",
            "Epoch 254/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1773 - accuracy: 0.9354 - val_loss: 1.9856 - val_accuracy: 0.6110\n",
            "Epoch 255/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1870 - accuracy: 0.9368 - val_loss: 1.7470 - val_accuracy: 0.6220\n",
            "Epoch 256/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1958 - accuracy: 0.9344 - val_loss: 1.7096 - val_accuracy: 0.6160\n",
            "Epoch 257/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1822 - accuracy: 0.9368 - val_loss: 1.9241 - val_accuracy: 0.6260\n",
            "Epoch 258/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1775 - accuracy: 0.9396 - val_loss: 1.8226 - val_accuracy: 0.6320\n",
            "Epoch 259/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9356 - val_loss: 1.8081 - val_accuracy: 0.6200\n",
            "Epoch 260/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1845 - accuracy: 0.9374 - val_loss: 1.8669 - val_accuracy: 0.6250\n",
            "Epoch 261/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.2026 - accuracy: 0.9248 - val_loss: 1.6869 - val_accuracy: 0.6430\n",
            "Epoch 262/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9388 - val_loss: 1.7457 - val_accuracy: 0.6280\n",
            "Epoch 263/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1688 - accuracy: 0.9428 - val_loss: 1.8615 - val_accuracy: 0.6120\n",
            "Epoch 264/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1609 - accuracy: 0.9412 - val_loss: 1.9132 - val_accuracy: 0.6330\n",
            "Epoch 265/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1474 - accuracy: 0.9470 - val_loss: 1.8679 - val_accuracy: 0.6300\n",
            "Epoch 266/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1703 - accuracy: 0.9400 - val_loss: 1.9337 - val_accuracy: 0.6470\n",
            "Epoch 267/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.9446 - val_loss: 1.8828 - val_accuracy: 0.6250\n",
            "Epoch 268/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1619 - accuracy: 0.9470 - val_loss: 1.8980 - val_accuracy: 0.6240\n",
            "Epoch 269/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.9436 - val_loss: 1.8155 - val_accuracy: 0.6340\n",
            "Epoch 270/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1681 - accuracy: 0.9448 - val_loss: 1.7970 - val_accuracy: 0.6220\n",
            "Epoch 271/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1796 - accuracy: 0.9398 - val_loss: 1.9899 - val_accuracy: 0.6010\n",
            "Epoch 272/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1849 - accuracy: 0.9376 - val_loss: 1.7974 - val_accuracy: 0.6220\n",
            "Epoch 273/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.9364 - val_loss: 1.8075 - val_accuracy: 0.6210\n",
            "Epoch 274/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.9404 - val_loss: 1.8479 - val_accuracy: 0.6250\n",
            "Epoch 275/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1874 - accuracy: 0.9400 - val_loss: 1.7221 - val_accuracy: 0.6340\n",
            "Epoch 276/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1997 - accuracy: 0.9334 - val_loss: 1.8092 - val_accuracy: 0.6180\n",
            "Epoch 277/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1799 - accuracy: 0.9374 - val_loss: 1.7590 - val_accuracy: 0.6290\n",
            "Epoch 278/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1859 - accuracy: 0.9372 - val_loss: 1.9228 - val_accuracy: 0.6280\n",
            "Epoch 279/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1754 - accuracy: 0.9396 - val_loss: 1.9519 - val_accuracy: 0.6020\n",
            "Epoch 280/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1810 - accuracy: 0.9402 - val_loss: 1.8318 - val_accuracy: 0.6190\n",
            "Epoch 281/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1726 - accuracy: 0.9402 - val_loss: 1.8013 - val_accuracy: 0.6100\n",
            "Epoch 282/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1655 - accuracy: 0.9420 - val_loss: 1.9318 - val_accuracy: 0.6270\n",
            "Epoch 283/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1707 - accuracy: 0.9438 - val_loss: 1.9411 - val_accuracy: 0.6120\n",
            "Epoch 284/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1576 - accuracy: 0.9454 - val_loss: 1.9673 - val_accuracy: 0.6090\n",
            "Epoch 285/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9454 - val_loss: 1.9121 - val_accuracy: 0.6120\n",
            "Epoch 286/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.9456 - val_loss: 1.8004 - val_accuracy: 0.6000\n",
            "Epoch 287/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1781 - accuracy: 0.9380 - val_loss: 1.8413 - val_accuracy: 0.6200\n",
            "Epoch 288/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1675 - accuracy: 0.9426 - val_loss: 1.8797 - val_accuracy: 0.6180\n",
            "Epoch 289/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1522 - accuracy: 0.9452 - val_loss: 1.9037 - val_accuracy: 0.6130\n",
            "Epoch 290/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1770 - accuracy: 0.9386 - val_loss: 1.8539 - val_accuracy: 0.6130\n",
            "Epoch 291/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1579 - accuracy: 0.9466 - val_loss: 1.8473 - val_accuracy: 0.6260\n",
            "Epoch 292/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1643 - accuracy: 0.9438 - val_loss: 1.7701 - val_accuracy: 0.6000\n",
            "Epoch 293/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1629 - accuracy: 0.9450 - val_loss: 1.8429 - val_accuracy: 0.6280\n",
            "Epoch 294/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1623 - accuracy: 0.9458 - val_loss: 1.8428 - val_accuracy: 0.6040\n",
            "Epoch 295/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1798 - accuracy: 0.9376 - val_loss: 1.7707 - val_accuracy: 0.6260\n",
            "Epoch 296/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9422 - val_loss: 1.7947 - val_accuracy: 0.6370\n",
            "Epoch 297/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1742 - accuracy: 0.9392 - val_loss: 1.8653 - val_accuracy: 0.6180\n",
            "Epoch 298/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1608 - accuracy: 0.9486 - val_loss: 1.8247 - val_accuracy: 0.6310\n",
            "Epoch 299/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1600 - accuracy: 0.9504 - val_loss: 1.8495 - val_accuracy: 0.6220\n",
            "Epoch 300/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1737 - accuracy: 0.9432 - val_loss: 1.8149 - val_accuracy: 0.6280\n",
            "Epoch 301/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1764 - accuracy: 0.9390 - val_loss: 1.8243 - val_accuracy: 0.6310\n",
            "Epoch 302/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1439 - accuracy: 0.9544 - val_loss: 1.9257 - val_accuracy: 0.6280\n",
            "Epoch 303/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1879 - accuracy: 0.9350 - val_loss: 1.8220 - val_accuracy: 0.6330\n",
            "Epoch 304/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.9444 - val_loss: 1.8855 - val_accuracy: 0.6240\n",
            "Epoch 305/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1522 - accuracy: 0.9492 - val_loss: 1.9699 - val_accuracy: 0.6160\n",
            "Epoch 306/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1631 - accuracy: 0.9464 - val_loss: 1.9427 - val_accuracy: 0.6170\n",
            "Epoch 307/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.9450 - val_loss: 1.8287 - val_accuracy: 0.6300\n",
            "Epoch 308/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.9412 - val_loss: 1.7938 - val_accuracy: 0.6380\n",
            "Epoch 309/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1691 - accuracy: 0.9430 - val_loss: 1.8638 - val_accuracy: 0.6130\n",
            "Epoch 310/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1769 - accuracy: 0.9378 - val_loss: 1.8037 - val_accuracy: 0.6290\n",
            "Epoch 311/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1722 - accuracy: 0.9426 - val_loss: 1.7354 - val_accuracy: 0.6260\n",
            "Epoch 312/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9454 - val_loss: 1.7473 - val_accuracy: 0.6280\n",
            "Epoch 313/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1586 - accuracy: 0.9470 - val_loss: 1.8572 - val_accuracy: 0.6250\n",
            "Epoch 314/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1655 - accuracy: 0.9420 - val_loss: 1.7827 - val_accuracy: 0.6210\n",
            "Epoch 315/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1652 - accuracy: 0.9450 - val_loss: 1.8113 - val_accuracy: 0.6240\n",
            "Epoch 316/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1644 - accuracy: 0.9468 - val_loss: 1.8346 - val_accuracy: 0.6070\n",
            "Epoch 317/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9498 - val_loss: 1.7344 - val_accuracy: 0.6300\n",
            "Epoch 318/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1552 - accuracy: 0.9496 - val_loss: 1.7906 - val_accuracy: 0.6280\n",
            "Epoch 319/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1702 - accuracy: 0.9404 - val_loss: 1.9215 - val_accuracy: 0.6150\n",
            "Epoch 320/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1600 - accuracy: 0.9452 - val_loss: 1.9045 - val_accuracy: 0.6330\n",
            "Epoch 321/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1549 - accuracy: 0.9484 - val_loss: 1.8507 - val_accuracy: 0.6350\n",
            "Epoch 322/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1575 - accuracy: 0.9432 - val_loss: 1.8741 - val_accuracy: 0.6220\n",
            "Epoch 323/500\n",
            "157/157 [==============================] - 1s 5ms/step - loss: 0.1801 - accuracy: 0.9408 - val_loss: 1.8546 - val_accuracy: 0.6150\n",
            "Epoch 324/500\n",
            " 60/157 [==========>...................] - ETA: 0s - loss: 0.1365 - accuracy: 0.9490"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-679a9b0eec95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_small\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn_9Jj9Sq1fy",
        "outputId": "dabb6ca4-de01-4f14-e482-06ffba8399a3"
      },
      "source": [
        "history.history['loss']"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.214280366897583,\n",
              " 1.9326070547103882,\n",
              " 1.7934677600860596,\n",
              " 1.6837228536605835,\n",
              " 1.6226603984832764,\n",
              " 1.5715692043304443,\n",
              " 1.534558653831482,\n",
              " 1.4591823816299438,\n",
              " 1.416609525680542,\n",
              " 1.359880805015564,\n",
              " 1.3242580890655518,\n",
              " 1.3046398162841797,\n",
              " 1.255016803741455,\n",
              " 1.2316296100616455,\n",
              " 1.1909394264221191,\n",
              " 1.156951904296875,\n",
              " 1.1394253969192505,\n",
              " 1.0917081832885742,\n",
              " 1.0735435485839844,\n",
              " 1.0456113815307617,\n",
              " 1.0275452136993408,\n",
              " 1.0334696769714355,\n",
              " 0.9844216704368591,\n",
              " 0.9627681374549866,\n",
              " 0.925784170627594,\n",
              " 0.9186210036277771,\n",
              " 0.8945505023002625,\n",
              " 0.8887791037559509,\n",
              " 0.8470569252967834,\n",
              " 0.839529812335968,\n",
              " 0.8395275473594666,\n",
              " 0.7914660573005676,\n",
              " 0.7858813405036926,\n",
              " 0.7683588862419128,\n",
              " 0.7638227343559265,\n",
              " 0.7296891212463379,\n",
              " 0.7292983531951904,\n",
              " 0.7158567309379578,\n",
              " 0.7119841575622559,\n",
              " 0.6955416798591614,\n",
              " 0.6866500973701477,\n",
              " 0.6374523639678955,\n",
              " 0.6450610160827637,\n",
              " 0.6383510231971741,\n",
              " 0.6441854238510132,\n",
              " 0.6398721933364868,\n",
              " 0.6065850257873535,\n",
              " 0.606757402420044,\n",
              " 0.5969477295875549,\n",
              " 0.5752596855163574,\n",
              " 0.551246166229248,\n",
              " 0.5611705183982849,\n",
              " 0.5432460308074951,\n",
              " 0.5534031391143799,\n",
              " 0.5280460715293884,\n",
              " 0.5380669832229614,\n",
              " 0.5275683999061584,\n",
              " 0.5332337617874146,\n",
              " 0.5062560439109802,\n",
              " 0.5168924927711487,\n",
              " 0.5139009952545166,\n",
              " 0.48729613423347473,\n",
              " 0.49444258213043213,\n",
              " 0.4732193350791931,\n",
              " 0.4887543320655823,\n",
              " 0.5036666989326477,\n",
              " 0.46535199880599976,\n",
              " 0.4704287052154541,\n",
              " 0.4548487365245819,\n",
              " 0.45867329835891724,\n",
              " 0.4285936951637268,\n",
              " 0.4367106556892395,\n",
              " 0.44654664397239685,\n",
              " 0.4387248158454895,\n",
              " 0.43932032585144043,\n",
              " 0.43684476613998413,\n",
              " 0.4313849210739136,\n",
              " 0.4098447859287262,\n",
              " 0.4195472300052643,\n",
              " 0.416289359331131,\n",
              " 0.40424710512161255,\n",
              " 0.3940873146057129,\n",
              " 0.41659125685691833,\n",
              " 0.39681702852249146,\n",
              " 0.3867547810077667,\n",
              " 0.3769475817680359,\n",
              " 0.40297409892082214,\n",
              " 0.38884058594703674,\n",
              " 0.3944337069988251,\n",
              " 0.3899967074394226,\n",
              " 0.3810248374938965,\n",
              " 0.3705311417579651,\n",
              " 0.36227428913116455,\n",
              " 0.38983994722366333,\n",
              " 0.38340097665786743,\n",
              " 0.3575594127178192,\n",
              " 0.35918012261390686,\n",
              " 0.35181185603141785,\n",
              " 0.35291755199432373,\n",
              " 0.3574887216091156]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjYAVEpKsiAk",
        "outputId": "4920b8e7-bf34-43f6-cbcc-70e4e096539c"
      },
      "source": [
        "model.evaluate(X_test_small, y_test_small, batch_size=32, verbose=0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8800930976867676, 0.6259999871253967]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcPQtVjdVj06"
      },
      "source": [
        "❓ **Question** ❓ Run the following function on the previous history (keep the default arguments, these are intended for future plots in the notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIR_L7UfVj06"
      },
      "source": [
        "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
        "    if axs is not None:\n",
        "        ax1, ax2 = axs\n",
        "    else:\n",
        "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    \n",
        "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
        "        exp_name = '_' + exp_name\n",
        "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
        "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
        "    ax1.set_ylim(0., 2.2)\n",
        "    ax1.set_title('loss')\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
        "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
        "    ax2.set_ylim(0.25, 1.)\n",
        "    ax2.set_title('Accuracy')\n",
        "    ax2.legend()\n",
        "    return (ax1, ax2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR7l9LxMVj07"
      },
      "source": [
        "❓ **Question** ❓ Evaluate your model on the test data and compare it with baseline. Are you satisfied with these performances ? Look at PRO TIPS above and iterate a bit if you want to improve!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0eVc9CuuwAx"
      },
      "source": [
        "history.history;"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "WwnwvmV5Vj08",
        "tags": [
          "challengify"
        ],
        "outputId": "febabfed-26ba-425a-fae3-40437895f0d3"
      },
      "source": [
        "plot_history(history, title='', axs=None, exp_name=\"\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<matplotlib.axes._subplots.AxesSubplot at 0x7f64b876bb50>,\n",
              " <matplotlib.axes._subplots.AxesSubplot at 0x7f64b870f290>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7P9y-LwVjdx"
      },
      "source": [
        "## 3. Increase data size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMHH_qsbVT_0"
      },
      "source": [
        "❓ **Question** ❓ Now that your model fits on a small subsample, try to fit it on the full dataset and notice how performance increases. \n",
        "\n",
        "🚨 **Make sure to use GPU acceleration** by clicking on `\"Runtime --> Change runtime --> GPU\"` if you are on Colab. \n",
        "\n",
        "💡 Training neural network on images (in each batch) can be parallelized, and this parallelization procedure can be done on GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWHicYsosW6o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2746d423-6565-4022-9d83-3bedf35b4bb3"
      },
      "source": [
        "history = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 50, batch_size = 32, verbose = 1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1152 - accuracy: 0.6168 - val_loss: 0.9572 - val_accuracy: 0.6687\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0420 - accuracy: 0.6414 - val_loss: 0.9229 - val_accuracy: 0.6842\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9963 - accuracy: 0.6559 - val_loss: 0.8888 - val_accuracy: 0.6941\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9642 - accuracy: 0.6691 - val_loss: 0.8687 - val_accuracy: 0.6971\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9247 - accuracy: 0.6820 - val_loss: 0.8370 - val_accuracy: 0.7157\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9072 - accuracy: 0.6864 - val_loss: 0.8246 - val_accuracy: 0.7102\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8906 - accuracy: 0.6901 - val_loss: 0.8082 - val_accuracy: 0.7247\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8706 - accuracy: 0.6970 - val_loss: 0.8376 - val_accuracy: 0.7101\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8562 - accuracy: 0.7038 - val_loss: 0.7784 - val_accuracy: 0.7312\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8397 - accuracy: 0.7083 - val_loss: 0.7615 - val_accuracy: 0.7377\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8366 - accuracy: 0.7123 - val_loss: 0.7925 - val_accuracy: 0.7314\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8204 - accuracy: 0.7160 - val_loss: 0.7628 - val_accuracy: 0.7389\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8088 - accuracy: 0.7179 - val_loss: 0.7672 - val_accuracy: 0.7349\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7997 - accuracy: 0.7217 - val_loss: 0.7449 - val_accuracy: 0.7459\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7927 - accuracy: 0.7239 - val_loss: 0.7573 - val_accuracy: 0.7413\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7870 - accuracy: 0.7236 - val_loss: 0.7631 - val_accuracy: 0.7370\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7748 - accuracy: 0.7289 - val_loss: 0.7499 - val_accuracy: 0.7401\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7757 - accuracy: 0.7303 - val_loss: 0.7457 - val_accuracy: 0.7487\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7611 - accuracy: 0.7359 - val_loss: 0.7493 - val_accuracy: 0.7414\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7620 - accuracy: 0.7353 - val_loss: 0.7604 - val_accuracy: 0.7401\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7529 - accuracy: 0.7368 - val_loss: 0.7280 - val_accuracy: 0.7532\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7470 - accuracy: 0.7402 - val_loss: 0.7570 - val_accuracy: 0.7421\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7444 - accuracy: 0.7420 - val_loss: 0.7417 - val_accuracy: 0.7440\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7361 - accuracy: 0.7430 - val_loss: 0.7293 - val_accuracy: 0.7450\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7302 - accuracy: 0.7458 - val_loss: 0.7462 - val_accuracy: 0.7426\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7286 - accuracy: 0.7460 - val_loss: 0.7303 - val_accuracy: 0.7547\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7216 - accuracy: 0.7451 - val_loss: 0.7766 - val_accuracy: 0.7352\n",
            "Epoch 28/50\n",
            " 443/1563 [=======>......................] - ETA: 4s - loss: 0.7247 - accuracy: 0.7455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5792b0643d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk8ZZVunVj08"
      },
      "source": [
        "## 4. Data augmentation\n",
        "\n",
        "☝️ It seems that adding pictures greatly improves model performance! Welcome to the Deep Learning paradigm, where big data does make a difference.\n",
        "\n",
        "To easily improve the accuracy of a model without much work, we can generate new data: the _data augmentation_. This widely used technique consists in applying little transformation to input images without changing its label, as mirroring, cropping, intensity changes, etc. The improved performance simply results from the Neural network training with more different data.\n",
        "\n",
        "The natural way to generate these new images is to apply some transformations and train the model on the original and new images. However, such procedure requires to keep all these images in memory : it can be very intensive, to the point that your computer memory cannot hold any new image (your computer might even crash).\n",
        "\n",
        "For this reason, we will augment the data **on the fly** (batch per batch), meaning that we will create new data, use them to fit the model, then delete them. Here, Keras is our friend as it provides the utils to do all this job for us. Look at the following code : the general writing can seem odd but don't be panicked: just look at the function arguments that defines the augmentation techniques that we will use and that you can check in the  [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T17:30:44.981000Z",
          "start_time": "2021-04-28T17:30:43.704837Z"
        },
        "id": "DlOpbos5Vj09",
        "scrolled": false
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    featurewise_std_normalization=False,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=(0.8, 1.2),\n",
        "    ) \n",
        "\n",
        "datagen.fit(X_train)\n",
        "datagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-28T17:30:45.856304Z",
          "start_time": "2021-04-28T17:30:45.471890Z"
        },
        "id": "Zcl17dW1aA0G"
      },
      "source": [
        "X_augmented_iterator = datagen.flow(X_train, shuffle=False, batch_size=1)\n",
        "X_augmented_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdMqg8grVj09"
      },
      "source": [
        "💡 Always visualize your data augmentation in order to double check that you can still recognize the label yourself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsqMF0adVj09",
        "scrolled": true
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for i, (raw_image, augmented_image) in enumerate(zip(X_train, X_augmented_iterator)):\n",
        "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
        "    ax1.imshow(raw_image)\n",
        "    ax2.imshow(augmented_image[0])\n",
        "    plt.show()\n",
        "    \n",
        "    if i > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyLlJQrKVj09"
      },
      "source": [
        "❗ **Remark** ❗ In this example, there is one augmented image per initial image. In fact, when your model will use `datagen.flow` in the `fit`, it will create one augmentation per epochs! Indeed, the images in the original dataset will not be provided to the optimizer, only augmented ones instead. (But because the augmentations are performed randomly, this allows both modified images and some very close of the originals).\n",
        "\n",
        "❓ **Question** ❓ Take time to understand the cell below: Previously, we used the `validation_split` argument to let the model separate a training set from the validation one. It is not possible here as **using an image in the training set and its transformation in the validation set is considered as a data leakage**. Therefore, we have to manually define the `validation_data` with the following commands:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYOkY7LOVj09"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# The model\n",
        "model_aug = initialize_model()\n",
        "model_aug = compile_model(model_aug)\n",
        "\n",
        "# The data generator\n",
        "X_tr = X_train[:40000]\n",
        "y_tr = y_train[:40000]\n",
        "X_val = X_train[40000:]\n",
        "y_val = y_train[40000:]\n",
        "train_flow = datagen.flow(X_tr, y_tr, batch_size=64)\n",
        "\n",
        "# The early stopping criterion\n",
        "es = EarlyStopping(patience=3)\n",
        "\n",
        "# The fit\n",
        "history_aug = model_aug.fit(train_flow, \n",
        "                        epochs=50, \n",
        "                        callbacks=[es], \n",
        "                        validation_data=(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmQ9t_cMVj0-"
      },
      "source": [
        "❗️❗️ Remark ❗️❗️: The training can be quite long here. Don't hesitate to go to the next exercise and gome back once in a while to finish the last questions\n",
        "\n",
        "❓ **Question** ❓ Now, let's plot the previous and current run histories. What do you think of the data augmentation?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9r4Fau2Vj0-",
        "tags": [
          "challengify"
        ]
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm055RyNVj0-"
      },
      "source": [
        "💡 Data augmentation may not improve your performance easily. It strongly depends on the model architecture you used, the learning rate, the type of augmentation chosen, etc...Image classification is an art that takes lots of practice to master!\n",
        "\n",
        "🚨 **Don't spend too much time now trying to finetune your model - you have other interesting challenge ahead**. \n",
        "\n",
        "📚 [here is a good example of solution for future reference](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/). They manage to get about 80% accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy4DCYLGVj0-"
      },
      "source": [
        "### 🏁 Congratulation 🏁 \n",
        "Copy this notebook from your google drive into your local data-challenge repo, and commit+push your progress on github. To find where this Colab notebook has been save, click on `File --> Locate in Drive`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkYuyP0_vdl2"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}